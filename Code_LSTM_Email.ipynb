{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GNfA36S3o93X",
        "nP5J_khULDHZ",
        "vfXq6_rvXbZx",
        "Voq6qIZy29i6",
        "V-PmM7AsBotz",
        "Zvz1meqApVHE"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNfA36S3o93X"
      },
      "source": [
        "### **FUNCTIONS and Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciuU7Ycro8P0"
      },
      "outputs": [],
      "source": [
        "def dataSplit(tup):\n",
        "    n = len(tup)\n",
        "    return tup[0 : (n - 1)]\n",
        "\n",
        "def labelSplit(tup):\n",
        "    n = len(tup)\n",
        "    return tup[n - 1]\n",
        "\n",
        "# get word from dictionary ID\n",
        "def getWord(d, i):\n",
        "    return list(d.keys())[list(d.values()).index(i)]\n",
        "\n",
        "#this function generates random numbers for the secret\n",
        "def generateSecret(length, size):\n",
        "    secret = \"\"\n",
        "    for i in range(length):\n",
        "        a = randint(0, size)\n",
        "        if a < 10:\n",
        "            a = \"0\" + str(a)\n",
        "        a = str(a)\n",
        "        secret = secret + a + \" \"\n",
        "    \n",
        "    return secret[:-1]\n",
        "\n",
        "#allows us to add every secret permutation to the \"test\" data set, allowing us to see what probability the model assigns to every value of r\n",
        "def enumerateSecrets(length, size, rid, pref):\n",
        "    d = []\n",
        "    \n",
        "    if length == 1:\n",
        "        for i in range(size):\n",
        "            a = pref + str(i)\n",
        "            d.append({'id' : rid,\n",
        "                      'text' : a,\n",
        "                      'noPunc' : a,\n",
        "                      'splchk' : a})\n",
        "            rid += 1\n",
        "    \n",
        "    if length == 2:\n",
        "        for i in range(size):\n",
        "            a = pref + str(i)\n",
        "            for j in range(size):\n",
        "                b = a + \" \" + str(j)\n",
        "                d.append({'id' : rid,\n",
        "                          'text' : b,\n",
        "                          'noPunc' : b,\n",
        "                          'splchk' : b})\n",
        "                rid += 1\n",
        "                \n",
        "    return d, rid\n",
        "\n",
        "def numericProbs(x, size, dictionary, gramSize, model, index): \n",
        "    xn = np.zeros((1, gramSize), dtype = float)\n",
        "    for k in range(gramSize):\n",
        "        xn[0][k] = x[index][k]\n",
        "\n",
        "    p0 = model.predict(xn)[0]\n",
        "    \n",
        "    numericProbs = np.zeros((size), dtype = float)\n",
        "    \n",
        "    for j in range(size):\n",
        "        a = str(j)\n",
        "        numericProbs[j] = p0[dictionary[a]]\n",
        "        \n",
        "    return numericProbs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FktCIKgUIgGS"
      },
      "outputs": [],
      "source": [
        "#cleaning\n",
        "import numpy as np\n",
        "import re\n",
        "from random import randint\n",
        "\n",
        "def cleanSMS(sms):\n",
        "    \n",
        "    # leetspeak\n",
        "    sms = re.sub(\"[\\.,]\", \" \", sms)\n",
        "    sms = re.sub(\" {2,}\", \" \", sms)\n",
        "    sms = re.sub(\" 2 \", \" to \", sms)\n",
        "    sms = re.sub(\" 4 | fr \", \" for \", sms)\n",
        "    \n",
        "    sms = re.sub(\" abt \", \" about \", sms)\n",
        "    sms = re.sub(\" aft \", \" after \", sms)\n",
        "    sms = re.sub(\" ard \", \" around \", sms)\n",
        "    \n",
        "    sms = re.sub(\" ar \", \" all right \", sms)\n",
        "    sms = re.sub(\" ar$\", \" all right\", sms)\n",
        "    \n",
        "    sms = re.sub(\" b \", \" be \", sms)\n",
        "    sms = re.sub(\" bcz \", \" because \", sms)\n",
        "    sms = re.sub(\" bday \", \" birthday\", sms)\n",
        "    sms = re.sub(\" brin \", \" bring \", sms)\n",
        "    \n",
        "    sms = re.sub(\" btw \", \" by the way \", sms)\n",
        "    sms = re.sub(\" btw$\", \" by the way\", sms)\n",
        "    \n",
        "    sms = re.sub(\" buk \", \" book \", sms)\n",
        "    \n",
        "    sms = re.sub(\" c \", \" see \", sms)\n",
        "    sms = re.sub(\"^c \", \"see \", sms)\n",
        "    \n",
        "    sms = re.sub(\" coz | cuz | cos \", \" cause \", sms)\n",
        "    sms = re.sub(\"^coz |^cuz |^cos \", \"cause \", sms)\n",
        "    \n",
        "    sms = re.sub(\" da \", \" the \", sms)\n",
        "    sms = re.sub(\" dat \", \" that \", sms)\n",
        "    \n",
        "    sms = re.sub(\" den \", \" then \", sms)\n",
        "    sms = re.sub(\"^den \", \"then \", sms)\n",
        "    sms = re.sub(\" den$\", \" then\", sms)\n",
        "    \n",
        "    sms = re.sub(\" dint? \", \" did not \", sms)\n",
        "    \n",
        "    sms = re.sub(\" dis \", \" this \", sms)\n",
        "    sms = re.sub(\" dis$\", \" this\", sms)\n",
        "    \n",
        "    sms = re.sub(\" dem | dm \", \" them \", sms)\n",
        "    sms = re.sub(\" dey \", \" they \", sms)\n",
        "    sms = re.sub(\"^dey \", \"they \", sms)\n",
        "    sms = re.sub(\" dnt \", \" do not \", sms)\n",
        "    \n",
        "    sms = re.sub(\" dun | don \", \" do not \", sms)\n",
        "    sms = re.sub(\"^dun |^don \", \"do not \", sms)\n",
        "    sms = re.sub(\" dun$| don$\", \" do not\", sms)\n",
        "    \n",
        "    sms = re.sub(\" e \", \" the \", sms)\n",
        "    sms = re.sub(\" esp \" , \" especially \", sms)\n",
        "    sms = re.sub(\" enuff \", \" enough \", sms)\n",
        "    sms = re.sub(\" frens \", \" friends \", sms)\n",
        "    \n",
        "    sms = re.sub(\" fren \" , \" friend \", sms)\n",
        "    sms = re.sub(\" fren$\", \" fren\", sms)\n",
        "    \n",
        "    sms = re.sub(\" frm \", \" from \", sms)\n",
        "    \n",
        "    sms = re.sub(\" gd \", \" good \", sms)\n",
        "    sms = re.sub(\"^gd \", \"good \", sms)\n",
        "    sms = re.sub(\" gd$\", \" good\", sms)\n",
        "    \n",
        "    sms = re.sub(\" gn \", \" good night \", sms)\n",
        "    sms = re.sub(\"^gn \", \"good night \", sms)\n",
        "    sms = re.sub(\" gn$\", \" good night\", sms)\n",
        "    \n",
        "    sms = re.sub(\"^hai \", \"hey \", sms)\n",
        "    \n",
        "    sms = re.sub(\" haf | hv | hav \", \" have \", sms)\n",
        "    sms = re.sub(\" haf$| hv$| hav$\", \" have\", sms)\n",
        "    \n",
        "    sms = re.sub(\" haven \", \" have not \", sms)\n",
        "    \n",
        "    sms = re.sub(\" hse \", \" house \", sms)\n",
        "    sms = re.sub(\" hse$\", \" house\", sms)\n",
        "    sms = re.sub(\" hw \", \" homework \", sms)\n",
        "    sms = re.sub(\"^hw \", \"how \", sms)\n",
        "    \n",
        "    sms = re.sub(\" i ll \", \" i will \", sms)\n",
        "    sms = re.sub(\"^i ll \", \"i will \", sms)\n",
        "    sms = re.sub(\" i ve \", \" i have \", sms)\n",
        "    sms = re.sub(\"^i ve \", \"i have \", sms)\n",
        "    \n",
        "    sms = re.sub(\" juz | jus | jos \", \" just \", sms)\n",
        "    sms = re.sub(\"^juz |^jus |^jos \", \"just \", sms)\n",
        "    \n",
        "    sms = re.sub(\"kd \", \"ked \", sms)\n",
        "    sms = re.sub(\" knw \", \" know \", sms)\n",
        "    \n",
        "    sms = re.sub(\" lar | lter \", \" later \", sms)\n",
        "    sms = re.sub(\" lar$| lter$\", \" later\", sms)\n",
        "    sms = re.sub(\"^lar |^lter \", \"later \", sms)\n",
        "    \n",
        "    sms = re.sub(\" lib \", \" library \", sms)\n",
        "    sms = re.sub(\" lib$\", \" library\", sms)\n",
        "    \n",
        "    sms = re.sub(\" lect \", \" lecture \", sms)\n",
        "    sms = re.sub(\"^ll \", \"i will \", sms)\n",
        "    sms = re.sub(\" lyk \", \" like \", sms)\n",
        "    sms = re.sub(\" m \", \" am \", sms)\n",
        "    sms = re.sub(\"^m \", \"i am \", sms)\n",
        "    sms = re.sub(\" mayb \", \" maybe \", sms)\n",
        "    sms = re.sub(\" meh \", \" me \", sms)\n",
        "    sms = re.sub(\" msg \", \" message \", sms)\n",
        "    sms = re.sub(\" neva \", \" never \", sms)\n",
        "    sms = re.sub(\" mum \", \" mom \", sms)\n",
        "    sms = re.sub(\" muz \", \" must \", sms)\n",
        "    sms = re.sub(\" n \", \" and \", sms)\n",
        "    sms = re.sub(\"nd \", \"ned \", sms)\n",
        "    sms = re.sub(\" nite \", \" night \", sms)\n",
        "    sms = re.sub(\" noe \", \" know \", sms)\n",
        "    \n",
        "    sms = re.sub(\" nt \", \" not \", sms)\n",
        "    sms = re.sub(\"^nt \", \"not \", sms)\n",
        "    \n",
        "    sms = re.sub(\" nvm \", \" never mind \", sms)\n",
        "    sms = re.sub(\" nvr \", \" never \", sms)\n",
        "    sms = re.sub(\" nw \", \" now \", sms)\n",
        "    \n",
        "    sms = re.sub(\" nxt \", \" next \", sms)\n",
        "    sms = re.sub(\"^nxt \", \"next \", sms)\n",
        "    \n",
        "    sms = re.sub(\" okie | ok | k \", \" okay \", sms)\n",
        "    sms = re.sub(\"^okie |^ok |^k \", \"okay \", sms)\n",
        "    sms = re.sub(\" okie$| ok$| k$\", \" okay\", sms)\n",
        "    \n",
        "    sms = re.sub(\" oredi | alr \", \" already \", sms)\n",
        "    sms = re.sub(\" oredi$| alr$\", \" already\", sms)\n",
        "    \n",
        "    sms = re.sub(\" oso \", \" also \", sms)\n",
        "    \n",
        "    sms = re.sub(\" plz \", \" please \", sms)\n",
        "    sms = re.sub(\"^plz \", \"please \", sms)\n",
        "    sms = re.sub(\" plz$\", \" please\", sms)\n",
        "    \n",
        "    sms = re.sub(\" pple? \", \" people \", sms)\n",
        "    \n",
        "    sms = re.sub(\" pg \", \" page \", sms)\n",
        "    sms = re.sub(\" pg$\", \" page\", sms)\n",
        "    \n",
        "    sms = re.sub(\" r \", \" are \", sms)\n",
        "    sms = re.sub(\"^r \", \"are \", sms)\n",
        "    sms = re.sub(\" r$\", \" are\", sms)\n",
        "    \n",
        "    sms = re.sub(\" rem \", \" remember \", sms)\n",
        "    sms = re.sub(\" rite \", \" right \", sms)\n",
        "    \n",
        "    sms = re.sub(\" rly \", \" really \", sms)\n",
        "    sms = re.sub(\"^rly \", \"really \", sms)\n",
        "    sms = re.sub(\" rly$\", \" really\", sms)\n",
        "    \n",
        "    sms = re.sub(\" ru \", \" are you \", sms)\n",
        "    sms = re.sub(\" s \", \" is \", sms)\n",
        "    sms = re.sub(\"^s \", \"its \", sms)\n",
        "    \n",
        "    sms = re.sub(\" sch \", \" school \", sms)\n",
        "    sms = re.sub(\" sch$\", \" school\", sms)\n",
        "    \n",
        "    sms = re.sub(\" shd | shld \", \" should \", sms)\n",
        "    sms = re.sub(\" slp \", \" sleep \", sms)\n",
        "    \n",
        "    sms = re.sub(\" sme\", \" some\", sms)\n",
        "    sms = re.sub(\"^sme\", \"some\", sms)\n",
        "    \n",
        "    sms = re.sub(\" smth \", \" something \", sms)\n",
        "    \n",
        "    sms = re.sub(\" tat \", \" that \", sms)\n",
        "    sms = re.sub(\"^tat \", \"that \", sms)\n",
        "    sms = re.sub(\" tat$\", \" that\", sms)\n",
        "    \n",
        "    sms = re.sub(\" tmr | tml \", \" tomorrow \", sms)\n",
        "    sms = re.sub(\"^tmr |^tml \", \"tomorrow \", sms)\n",
        "    sms = re.sub(\" tmr$| tml$\", \" tomorrow\", sms)\n",
        "    \n",
        "    sms = re.sub(\" thanx \", \" thanks \", sms)\n",
        "    sms = re.sub(\" thanx$\", \" thanks\", sms)\n",
        "    sms = re.sub(\"^thanx \", \"thanks \", sms)\n",
        "    \n",
        "    sms = re.sub(\" thgt \", \" thought \", sms)\n",
        "    sms = re.sub(\" thk | thnk \", \" think \", sms)\n",
        "    sms = re.sub(\" tis \", \" this \", sms)\n",
        "    sms = re.sub(\" tot \" , \" thought \", sms)\n",
        "    sms = re.sub(\" ttyl$\", \" talk to you later\", sms)\n",
        "    \n",
        "    sms = re.sub(\" tym \", \" time \", sms)\n",
        "    sms = re.sub(\" tym\", \" time\", sms)\n",
        "    \n",
        "    sms = re.sub(\" [uüü] \", \" you \", sms)\n",
        "    sms = re.sub(\"^[uüü] \", \"you \", sms)\n",
        "    sms = re.sub(\" [uüü]$\", \" you\", sms)\n",
        "    \n",
        "    sms = re.sub(\" ur \", \" your \", sms)\n",
        "    sms = re.sub(\" v \", \" very \", sms)\n",
        "    sms = re.sub(\" vil \", \" will \", sms)\n",
        "    sms = re.sub(\"^ve \", \"i have \", sms)\n",
        "    sms = re.sub(\" wan \", \" want \", sms)\n",
        "    sms = re.sub(\" w \", \" with \", sms)\n",
        "    \n",
        "    sms = re.sub(\" wana \", \" wanna \", sms)\n",
        "    sms = re.sub(\"^wana \", \"wanna \", sms)\n",
        "    \n",
        "    sms = re.sub(\" wat \", \" what \", sms)\n",
        "    sms = re.sub(\"^wat \", \"what \", sms)\n",
        "    sms = re.sub(\" wat$\", \" what\", sms)\n",
        "    \n",
        "    sms = re.sub(\" wen \", \" when \", sms)\n",
        "    sms = re.sub(\"^wen \", \"when \", sms)\n",
        "    \n",
        "    sms = re.sub(\" wif | wid | wth \", \" with \", sms)\n",
        "    sms = re.sub(\"^wif |^wid |^wth \", \"with \", sms)\n",
        "    sms = re.sub(\" wif$| wid$| wth$\", \" with\", sms)\n",
        "    \n",
        "    sms = re.sub(\" wk \", \" week \", sms)\n",
        "\n",
        "    sms = re.sub(\" wun \", \" wont \", sms)\n",
        "    \n",
        "    sms = re.sub(\" y \", \" why \", sms)\n",
        "    sms = re.sub(\"^y \", \"why \", sms)\n",
        "    sms = re.sub(\" y$\", \" why\", sms)\n",
        "    \n",
        "    sms = re.sub(\"yup\", \"yep\", sms)\n",
        "\n",
        "    # remove laughter and smiles\n",
        "    sms = re.sub(\" d \", \" \", sms)\n",
        "    sms = re.sub(\" d$\", \"\", sms)\n",
        "    sms = re.sub(\"^d \", \"\", sms)\n",
        "    sms = re.sub(\" ha \", \" \", sms)\n",
        "    sms = re.sub(\"^ha \", \"\", sms)\n",
        "    sms = re.sub(\" ha$, \", \"\", sms)\n",
        "    sms = re.sub(\" lor \", \" \", sms)\n",
        "    sms = re.sub(\" lor$\", \"\", sms)\n",
        "    sms = re.sub(\" lols? \", \" \", sms)\n",
        "    sms = re.sub(\"^lols? \", \"\", sms)\n",
        "    sms = re.sub(\" lols?$\", \"\", sms)\n",
        "    sms = re.sub(\"a*(ha){2,}h*\", \"\", sms)\n",
        "    sms = re.sub(\" hee \", \" \", sms)\n",
        "    sms = re.sub(\"^hee \", \"\", sms)\n",
        "    sms = re.sub(\" hee$\", \"\", sms)\n",
        "    \n",
        "    # remove words I don't understand\n",
        "    sms = re.sub(\" lei \", \" \", sms)\n",
        "    sms = re.sub(\"^lei \", \" \", sms)\n",
        "    sms = re.sub(\" lei$\", \" \", sms)\n",
        "    \n",
        "    # standardize most '-ing' to '-in'\n",
        "    sms = re.sub(\"(?<=[bdfghklmnoprstvwy])ing(?= )\", \"in\", sms)\n",
        "    sms = re.sub(\"(?<=[bdfghklmnoprstvwy])ing$\", \"in\", sms)\n",
        "    \n",
        "    # force spaces between comma- or period-separated words\n",
        "    sms = re.sub(\"(?<=[^ ])[\\.,](?=[^ ])\", \" \", sms)\n",
        "    \n",
        "    return sms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSaQMOemHUmU"
      },
      "outputs": [],
      "source": [
        "import sys, os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from nltk import ngrams\n",
        "from math import log\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Email DATA** statistics for the presentation"
      ],
      "metadata": {
        "id": "nv82nqOdK9Ry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "statistics"
      ],
      "metadata": {
        "id": "sRuitT9NL6qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wteF0Z5z_8gc",
        "outputId": "5b98e3c4-b7cd-4b05-ecb5-d68536bc9b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/emails.csv')"
      ],
      "metadata": {
        "id": "0S3AawHQDLns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2F65P6DDVXW",
        "outputId": "01a55b65-d249-4bff-d40f-5b15e6f327d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(517401, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email = pd.DataFrame(email)\n",
        "email.rename(columns = {'file':'id','message':'text'}, inplace = True)\n",
        "email['text'] = email['text'].astype(\"str\")\n",
        "email['text'] = email['text'].map(lambda x: x.lstrip(\"{'$':-\").rstrip(\"-'}\"))\n",
        "email['text'] = email['text'].str.replace(r\"'\", \"\")\n",
        "email.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a8d9b4-ab1d-4361-804f-7ae0127badf1",
        "id": "WWwb54faMAp_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(517401, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Cleaning"
      ],
      "metadata": {
        "id": "--ScB8wBOr6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Email_clean.csv')\n",
        "dataRaw = pd.DataFrame(dataRaw)\n",
        "dataRaw.rename(columns = {'file':'id','message':'text'}, inplace = True)\n",
        "dataRaw['text'] = dataRaw['text'].astype(\"str\")\n",
        "dataRaw['text'] = dataRaw['text'].map(lambda x: x.lstrip(\"{'$':-\").rstrip(\"-'}\"))\n",
        "dataRaw['text'] = dataRaw['text'].str.replace(r\"'\", \"\")\n",
        "dataRaw.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ed62dfee-1070-42e2-ddca-b8f55001c47e",
        "id": "Tba_QTq9OrMv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                        id  \\\n",
              "0           0     allen-p/_sent_mail/1.   \n",
              "1           1    allen-p/_sent_mail/10.   \n",
              "2           2   allen-p/_sent_mail/100.   \n",
              "3           3  allen-p/_sent_mail/1000.   \n",
              "4           4  allen-p/_sent_mail/1001.   \n",
              "\n",
              "                                                text  \n",
              "0      pallen nonprivileged pst here is our forecast  \n",
              "1  pallen nonprivileged pst travelin to have a bu...  \n",
              "2               pallen nsf test successful way to go  \n",
              "3  pallen nsf randy can you sened me a schedule o...  \n",
              "4               pallen nsf lets shoot for tuesday at  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea7fb5d9-7cc5-4863-8dc9-b9040b58a7d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>pallen nonprivileged pst here is our forecast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>pallen nonprivileged pst travelin to have a bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>allen-p/_sent_mail/100.</td>\n",
              "      <td>pallen nsf test successful way to go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>pallen nsf randy can you sened me a schedule o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>allen-p/_sent_mail/1001.</td>\n",
              "      <td>pallen nsf lets shoot for tuesday at</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea7fb5d9-7cc5-4863-8dc9-b9040b58a7d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea7fb5d9-7cc5-4863-8dc9-b9040b58a7d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea7fb5d9-7cc5-4863-8dc9-b9040b58a7d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b965eacb-2512-4169-dd15-97dbec4dc296",
        "id": "T5I1USraOrMw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(365397, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw['vocabsplit'] = dataRaw.text.str.split()"
      ],
      "metadata": {
        "id": "rJua_oAWRWkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw['vocablen'] = 0"
      ],
      "metadata": {
        "id": "er_cgKE4AQHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataRaw)):\n",
        "  dataRaw['vocablen'][i] = len(dataRaw['vocabsplit'][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sXDm00LQ1lf",
        "outputId": "a8be1997-b6e1-4979-fbf9-472226e5af2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-26f591577e28>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataRaw['vocablen'][i] = len(dataRaw['vocabsplit'][i])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(dataRaw['vocablen'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhmgGgIlO1H0",
        "outputId": "f9f5c618-f6b3-44a5-ed98-30f47f07c120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(dataRaw['vocablen'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9cc641-855a-4173-f3c4-eb5afe681f1b",
        "id": "7qJeS8L9OrMw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import mean\n",
        "mean(dataRaw['vocablen'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdIOvAg9O2h0",
        "outputId": "5c804cbb-2025-4942-edfd-78d6e3fe43cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61.614186761248725"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in dataRaw['text']]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 50, color = \"navy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ffbYZmLZO_eP",
        "outputId": "79584231-5111-4fb5-8eb5-4ad7f55886e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe54966f400>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "seq_len = [len(i.split()) for i in dataRaw['text']]\n",
        "plt.hist(pd.Series(seq_len),bins = 50, color = \"navy\")\n",
        "plt.xlabel('Vocab Length for each Email')\n",
        "plt.ylabel('Frequency')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "rVqcEDsPFlk8",
        "outputId": "6d1e27b6-c299-49af-8bce-67cfe9248edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data and Cleaning Process**"
      ],
      "metadata": {
        "id": "nP5J_khULDHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WO7cKbXMtiy",
        "outputId": "a9d81d77-7854-4449-dcbd-18ddff2ad5c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SAjt5aQosyC"
      },
      "source": [
        "**Email data - Cleaning Process**\n",
        "the data is one time cleaned and is saved as csv "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Email_clean.csv')\n",
        "dataRaw = pd.DataFrame(dataRaw)\n",
        "dataRaw.rename(columns = {'file':'id','message':'text'}, inplace = True)\n",
        "dataRaw['text'] = dataRaw['text'].astype(\"str\")\n",
        "dataRaw['text'] = dataRaw['text'].map(lambda x: x.lstrip(\"{'$':-\").rstrip(\"-'}\"))\n",
        "dataRaw['text'] = dataRaw['text'].str.replace(r\"'\", \"\")\n",
        "dataRaw.head()"
      ],
      "metadata": {
        "id": "-GAjKCDXvMFb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "dd3b415e-4e66-4e15-8d7f-e6579caca9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                        id  \\\n",
              "0           0     allen-p/_sent_mail/1.   \n",
              "1           1    allen-p/_sent_mail/10.   \n",
              "2           2   allen-p/_sent_mail/100.   \n",
              "3           3  allen-p/_sent_mail/1000.   \n",
              "4           4  allen-p/_sent_mail/1001.   \n",
              "\n",
              "                                                text  \n",
              "0      pallen nonprivileged pst here is our forecast  \n",
              "1  pallen nonprivileged pst travelin to have a bu...  \n",
              "2               pallen nsf test successful way to go  \n",
              "3  pallen nsf randy can you sened me a schedule o...  \n",
              "4               pallen nsf lets shoot for tuesday at  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d79e826-262c-40fa-95f9-4687cc1f7800\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>pallen nonprivileged pst here is our forecast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>pallen nonprivileged pst travelin to have a bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>allen-p/_sent_mail/100.</td>\n",
              "      <td>pallen nsf test successful way to go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>pallen nsf randy can you sened me a schedule o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>allen-p/_sent_mail/1001.</td>\n",
              "      <td>pallen nsf lets shoot for tuesday at</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d79e826-262c-40fa-95f9-4687cc1f7800')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d79e826-262c-40fa-95f9-4687cc1f7800 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d79e826-262c-40fa-95f9-4687cc1f7800');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw.shape"
      ],
      "metadata": {
        "id": "bHW2clBr_umv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec7aa79-afc5-4ec6-e937-670334ec5d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(365397, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw['length'] = dataRaw.text.str.len()\n"
      ],
      "metadata": {
        "id": "amLQ-Sm_zv4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min(dataRaw['length'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6ACNsQjLjL0",
        "outputId": "aa201d8a-c0c5-4ab6-cd2b-e11aee645fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "o5aBsQnAOYlb",
        "outputId": "c5c2eee6-2cc5-42d0-e118-bf5beb30c1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0                         id  \\\n",
              "0                0      allen-p/_sent_mail/1.   \n",
              "1                1     allen-p/_sent_mail/10.   \n",
              "2                2    allen-p/_sent_mail/100.   \n",
              "3                3   allen-p/_sent_mail/1000.   \n",
              "4                4   allen-p/_sent_mail/1001.   \n",
              "...            ...                        ...   \n",
              "365392      517395  zufferli-j/sent_items/94.   \n",
              "365393      517396  zufferli-j/sent_items/95.   \n",
              "365394      517397  zufferli-j/sent_items/96.   \n",
              "365395      517398  zufferli-j/sent_items/97.   \n",
              "365396      517399  zufferli-j/sent_items/98.   \n",
              "\n",
              "                                                     text  length  \n",
              "0           pallen nonprivileged pst here is our forecast      45  \n",
              "1       pallen nonprivileged pst travelin to have a bu...     787  \n",
              "2                    pallen nsf test successful way to go      36  \n",
              "3       pallen nsf randy can you sened me a schedule o...     188  \n",
              "4                    pallen nsf lets shoot for tuesday at      36  \n",
              "...                                                   ...     ...  \n",
              "365392  hi are things a little less crazy today did yo...     497  \n",
              "365393  john zufferli   pst this is a trade with oilsp...     253  \n",
              "365394  john zufferli   pst some of my position is wit...     135  \n",
              "365395  confidential mornin john im still workin on th...     192  \n",
              "365396  john zufferli   pst analyst rank stephane brod...     143  \n",
              "\n",
              "[365397 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3768bdcf-fa43-4308-8db8-156cde7e273a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>pallen nonprivileged pst here is our forecast</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>pallen nonprivileged pst travelin to have a bu...</td>\n",
              "      <td>787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>allen-p/_sent_mail/100.</td>\n",
              "      <td>pallen nsf test successful way to go</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>pallen nsf randy can you sened me a schedule o...</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>allen-p/_sent_mail/1001.</td>\n",
              "      <td>pallen nsf lets shoot for tuesday at</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365392</th>\n",
              "      <td>517395</td>\n",
              "      <td>zufferli-j/sent_items/94.</td>\n",
              "      <td>hi are things a little less crazy today did yo...</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365393</th>\n",
              "      <td>517396</td>\n",
              "      <td>zufferli-j/sent_items/95.</td>\n",
              "      <td>john zufferli   pst this is a trade with oilsp...</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365394</th>\n",
              "      <td>517397</td>\n",
              "      <td>zufferli-j/sent_items/96.</td>\n",
              "      <td>john zufferli   pst some of my position is wit...</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365395</th>\n",
              "      <td>517398</td>\n",
              "      <td>zufferli-j/sent_items/97.</td>\n",
              "      <td>confidential mornin john im still workin on th...</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365396</th>\n",
              "      <td>517399</td>\n",
              "      <td>zufferli-j/sent_items/98.</td>\n",
              "      <td>john zufferli   pst analyst rank stephane brod...</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>365397 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3768bdcf-fa43-4308-8db8-156cde7e273a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3768bdcf-fa43-4308-8db8-156cde7e273a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3768bdcf-fa43-4308-8db8-156cde7e273a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataRaw = dataRaw[dataRaw.length < 70]"
      ],
      "metadata": {
        "id": "-eO4QRagz__X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataRaw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afgMRBsW0O_v",
        "outputId": "75264288-ffc2-4e4e-bf0f-d57ad4950a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42367"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rootId = len(dataRaw)"
      ],
      "metadata": {
        "id": "wYJOPVFTGbrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVhBRKJJHkwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f902ad31-1d75-4267-8517-0e4873662e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-65-93d043b43abc>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataRaw['noPunc'] = dataRaw['text'].apply(\n",
            "<ipython-input-65-93d043b43abc>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataRaw['splchk'] = dataRaw['noPunc'].apply(cleanSMS)\n"
          ]
        }
      ],
      "source": [
        "#cleaning\n",
        "myPunc = '!\"#$%&\\()*+-/:;<=>?@[\\\\]^_`{|}~\\''\n",
        "dataRaw['noPunc'] = dataRaw['text'].apply(\n",
        "        lambda s: s.translate(str.maketrans('','', myPunc)).lower()\n",
        "        )\n",
        "\n",
        "dataRaw['splchk'] = dataRaw['noPunc'].apply(cleanSMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woHgaklYVyKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3647ce70-12b3-4e70-e58b-cd1771552adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-4425853eb877>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataRaw['splchk'] = dataRaw['noPunc'].apply(cleanSMS)\n",
            "<ipython-input-66-4425853eb877>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataRaw['splchk'] = dataRaw['splchk'].apply(cleanSMS)\n"
          ]
        }
      ],
      "source": [
        "#cleaning\n",
        "dataRaw['splchk'] = dataRaw['noPunc'].apply(cleanSMS)\n",
        "dataRaw['splchk'] = dataRaw['splchk'].apply(cleanSMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrPd3vjCVyHC"
      },
      "outputs": [],
      "source": [
        "#partitioning train, validation, test\n",
        "random.seed(10)\n",
        "#we have 20% of the whole data known as dataRaw for test and it is knwon as dataRawT\n",
        "#then the othe 80% is known as dataRawR will soon split to valid and train\n",
        "mskTrain = np.random.rand(len(dataRaw)) < 0.8\n",
        "dataRawR = dataRaw[mskTrain]\n",
        "dataRawT = dataRaw[~mskTrain]\n",
        "\n",
        "# train-validation split\n",
        "mskVal = np.random.rand(len(dataRawR)) < 0.8\n",
        "#Here from the left 80% of the data in dataRawR we have 80% for training known as dataRawR and 20% for validation known as dataRawV\n",
        "dataRawV = dataRawR[~mskVal]\n",
        "dataRawR = dataRawR[mskVal]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIejdCB9HRFM"
      },
      "source": [
        "###**SetUp data split and training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### exposure with no secret in the train set -- BASELINE"
      ],
      "metadata": {
        "id": "69SaEpd0CPI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # 0. EXPERIMENTAL SETUP ====================================\n",
        "\n",
        "  # how many copies of the secret do we insert?\n",
        "  numTrueSecrets = 0\n",
        "  # how many 'noisy' secrets do we insert?\n",
        "  numFalseSecrets = 0\n",
        "  # how many ticks are on our lock?\n",
        "  numDistinctValues = 100\n",
        "  # how long should we train the model?\n",
        "  numEpochs = 5\n",
        "  batchSize = 256\n",
        "\n",
        "  # what form should the secret take?\n",
        "  secretPref = \"my permanent code is \"\n",
        "  seqLength = len(secretPref.split())\n",
        "  gramSize = seqLength + 1\n",
        "\n",
        "  # randomness space\n",
        "  secretLength = 2\n",
        "  bigR = numDistinctValues ** secretLength\n",
        "\n",
        "  # generate a random secret\n",
        "  secretText = generateSecret(secretLength, numDistinctValues)\n",
        "  insertedSecret = secretPref + secretText\n",
        "\n",
        "  print(\"\\n+---------------------------------------+\")\n",
        "  print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
        "  print(\"+---------------------------------------+\\n\")\n",
        "  print(\" True secrets inserted:\", numTrueSecrets)\n",
        "  print(\" False secrets inserted:\", numFalseSecrets)\n",
        "  print(\" Randomness space:\", numDistinctValues)\n",
        "  print(\" Training epochs:\", numEpochs)\n",
        "  print(\" Batch size:\", batchSize)\n",
        "  print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
        "  print(\"-----------------------------------------\")\n",
        "  print(\"\\npreparing data...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbvBK9BxCYtP",
        "outputId": "ab926504-49ba-486d-c4ce-2a1cc3846d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+---------------------------------------+\n",
            "| THANK YOU FOR USING THE SECRET SHARER |\n",
            "+---------------------------------------+\n",
            "\n",
            " True secrets inserted: 0\n",
            " False secrets inserted: 0\n",
            " Randomness space: 100\n",
            " Training epochs: 5\n",
            " Batch size: 256\n",
            " Secret text: 'my permanent code is 73 01'\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "preparing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
        "#d here is all possible secrets\n",
        "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
        "# get some noise from these fake secret to add to training\n",
        "\n",
        "if numFalseSecrets > 0:\n",
        "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
        "    noiseDF = pd.DataFrame(noise)\n",
        "\n",
        "testSecret = pd.DataFrame(d);\n",
        "#test data has all possible secrets in it now\n",
        "dataRawT = dataRawT.append(d)\n",
        "#data for dct\n",
        "dataRawdct = dataRaw.append(d)\n",
        "\n",
        "# d = []\n",
        "# # several in training data\n",
        "# for i in range(numTrueSecrets):\n",
        "#     d.append({'id' : rootId,\n",
        "#               'text' : insertedSecret,\n",
        "#               'noPunc' : insertedSecret,\n",
        "#               'splchk' : insertedSecret})\n",
        "#     rootId += 1\n",
        "# #truesecrets add in train data\n",
        "# trainSecret = pd.DataFrame(d)\n",
        "#dataRawR = dataRawR.append(d)\n",
        "\n",
        "#also the noise is added to train set\n",
        "# if numFalseSecrets > 0:\n",
        "#     dataRawR = dataRawR.append(noiseDF)\n",
        "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
        "\n",
        "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
        "\n",
        "d = []\n",
        "gid = 0\n",
        "for i in range(len(dataRawR)):\n",
        "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsR = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawV)):\n",
        "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsV = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawT)):\n",
        "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsT = pd.DataFrame(d)"
      ],
      "metadata": {
        "id": "Kq09NVVHCsbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataGramsT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iL3S28ytCv4Y",
        "outputId": "69274859-49cd-45be-d4b3-cde8a56a71a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                  data\n",
              "0      124656   (pallen, nsf, any, mornin, between)\n",
              "1      124657     (nsf, any, mornin, between, aned)\n",
              "2      124658  (new, generation, sorry, report, as)\n",
              "3      124659   (generation, sorry, report, as, of)\n",
              "4      124660       (sorry, report, as, of, august)\n",
              "...       ...                                   ...\n",
              "51753  176409         (permanent, code, is, 99, 97)\n",
              "51754  176410         (my, permanent, code, is, 99)\n",
              "51755  176411         (permanent, code, is, 99, 98)\n",
              "51756  176412         (my, permanent, code, is, 99)\n",
              "51757  176413         (permanent, code, is, 99, 99)\n",
              "\n",
              "[51758 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17eefd25-4749-4ff6-bbce-4d3e80d1101c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>124656</td>\n",
              "      <td>(pallen, nsf, any, mornin, between)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>124657</td>\n",
              "      <td>(nsf, any, mornin, between, aned)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>124658</td>\n",
              "      <td>(new, generation, sorry, report, as)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>124659</td>\n",
              "      <td>(generation, sorry, report, as, of)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>124660</td>\n",
              "      <td>(sorry, report, as, of, august)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51753</th>\n",
              "      <td>176409</td>\n",
              "      <td>(permanent, code, is, 99, 97)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51754</th>\n",
              "      <td>176410</td>\n",
              "      <td>(my, permanent, code, is, 99)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51755</th>\n",
              "      <td>176411</td>\n",
              "      <td>(permanent, code, is, 99, 98)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51756</th>\n",
              "      <td>176412</td>\n",
              "      <td>(my, permanent, code, is, 99)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51757</th>\n",
              "      <td>176413</td>\n",
              "      <td>(permanent, code, is, 99, 99)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51758 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17eefd25-4749-4ff6-bbce-4d3e80d1101c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17eefd25-4749-4ff6-bbce-4d3e80d1101c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17eefd25-4749-4ff6-bbce-4d3e80d1101c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKr5VToLEn0P"
      },
      "outputs": [],
      "source": [
        "# word IDs\n",
        "#dct from dataRaw\n",
        "dct = dict()\n",
        "# word frequencies\n",
        "dctFreq = dict()\n",
        "did = 0\n",
        "for i in range(len(dataRawdct)):\n",
        "    s = dataRawdct.splchk.iloc[i].split()\n",
        "    for w in s:\n",
        "        if w not in dct:\n",
        "            dct[w] = did\n",
        "            did += 1\n",
        "            dctFreq[w] = 1\n",
        "        else:\n",
        "            dctFreq[w] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbo8glJ8En0P"
      },
      "outputs": [],
      "source": [
        "dctNoSingle = dict()\n",
        "did = 0\n",
        "for w in list(dct.keys()):\n",
        "    if dctFreq[w] !=1:\n",
        "        dctNoSingle[w] = did\n",
        "        did += 1\n",
        "        \n",
        "dct = dctNoSingle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05KARqLhEn0Q"
      },
      "outputs": [],
      "source": [
        "def noSingleUseWords(tup):\n",
        "    for w in tup:\n",
        "        if w not in dct:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "dataGramsR = dataGramsR[dataGramsR['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsT = dataGramsT[dataGramsT['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsV = dataGramsV[dataGramsV['data'].apply(noSingleUseWords) == True]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8238cf-c96f-454c-992a-e49b262bc1be",
        "id": "PP7LXLCDEn0Q"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-173b97ba434e>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
            "<ipython-input-29-173b97ba434e>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
          ]
        }
      ],
      "source": [
        "def encodeText(tup):\n",
        "    code = [None] * len(tup)\n",
        "    for i in range(len(tup)):\n",
        "        code[i] = dct[tup[i]]  \n",
        "    return tuple(code)\n",
        "\n",
        "dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n",
        "dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
        "dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9880c0c7-2305-45c0-a8e2-20e1f90fc4c0",
        "id": "xKRHzp_YEn0Q"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-8573288be9a1>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
            "<ipython-input-30-8573288be9a1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n"
          ]
        }
      ],
      "source": [
        "dataGramsR['x'] = dataGramsR['codes'].apply(dataSplit)\n",
        "dataGramsR['y'] = dataGramsR['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
        "dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsV['x'] = dataGramsV['codes'].apply(dataSplit)\n",
        "dataGramsV['y'] = dataGramsV['codes'].apply(labelSplit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcI2vlexEn0Q"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "xr = np.zeros((len(dataGramsR), seqLength), dtype = int) \n",
        "yr = np.zeros((len(dataGramsR)), dtype = int)\n",
        "for i in range(len(dataGramsR)):\n",
        "    for j in range(len(dataGramsR.x.iloc[i])):\n",
        "        xr[i][j] = dataGramsR.x.iloc[i][j]\n",
        "    yr[i] = dataGramsR.y.iloc[i]\n",
        "\n",
        "# validation\n",
        "xv = np.zeros((len(dataGramsV), seqLength), dtype = int)\n",
        "yv = np.zeros((len(dataGramsV)), dtype = int)    \n",
        "for i in range(len(dataGramsV)):\n",
        "    for j in range(len(dataGramsV.x.iloc[i])):\n",
        "        xv[i][j] = dataGramsV.x.iloc[i][j]\n",
        "    yv[i] = dataGramsV.y.iloc[i]\n",
        "    \n",
        "# testing\n",
        "xt = np.zeros((len(dataGramsT), seqLength), dtype = int)\n",
        "yt = np.zeros((len(dataGramsT)), dtype = int)\n",
        "for i in range(len(dataGramsT)):\n",
        "    for j in range(len(dataGramsT.x.iloc[i])):\n",
        "        xt[i][j] = dataGramsT.x.iloc[i][j]\n",
        "    yt[i] = dataGramsT.y.iloc[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to add numbers that are not in dictionary to the dictionary\n",
        "counter = len(dct)\n",
        "for i in range(150):\n",
        "  if str(i) not in dct:\n",
        "    counter += 1\n",
        "    dct[str(i)] = counter"
      ],
      "metadata": {
        "id": "udTUzR8HEn0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(dct)\n",
        "vocabSize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fb2e23-b57a-411d-dec2-1a5871b4a84f",
        "id": "qA5jDc72En0R"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8597"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhIhHdomEn0R"
      },
      "outputs": [],
      "source": [
        "# 5.1 ONE-HOT ENCODE LABEL DATA ----------------------------\n",
        "# training\n",
        "\n",
        "\n",
        "b = np.zeros((len(yr), vocabSize))\n",
        "b[np.arange(len(yr)), yr] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVLJJJmqEn0R"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "\n",
        "\n",
        "bv = np.zeros((len(yv), vocabSize))\n",
        "bv[np.arange(len(yv)), yv] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jasob86uEn0R"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "366a3a64-4eed-4fee-ba09-13c2e7cec86c",
        "id": "5JSQDHSGEn0S"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhRRXChBEn0S"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2vVAT3LEn0S"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nGGd_D_En0S"
      },
      "outputs": [],
      "source": [
        "# 5.2 COMPILE MODEL ----------------------------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabSize, seqLength, input_length = seqLength))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocabSize, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uMrPoVQEn0S"
      },
      "outputs": [],
      "source": [
        "#plot_model(model, to_file='LSTM_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7149ed3f-eae3-49c1-f4e2-c42bf1c8666c",
        "id": "rhQDl1vdEn0T"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model...\n",
            "Epoch 1/5\n",
            "381/381 [==============================] - 14s 15ms/step - loss: 6.9559 - accuracy: 0.0378 - val_loss: 6.6900 - val_accuracy: 0.0389\n",
            "Epoch 2/5\n",
            "381/381 [==============================] - 4s 11ms/step - loss: 6.5655 - accuracy: 0.0463 - val_loss: 6.4805 - val_accuracy: 0.0541\n",
            "Epoch 3/5\n",
            "381/381 [==============================] - 4s 11ms/step - loss: 6.2812 - accuracy: 0.0650 - val_loss: 6.1765 - val_accuracy: 0.0838\n",
            "Epoch 4/5\n",
            "381/381 [==============================] - 4s 11ms/step - loss: 5.9415 - accuracy: 0.0909 - val_loss: 5.9565 - val_accuracy: 0.1012\n",
            "Epoch 5/5\n",
            "381/381 [==============================] - 4s 11ms/step - loss: 5.6970 - accuracy: 0.1070 - val_loss: 5.7959 - val_accuracy: 0.1156\n"
          ]
        }
      ],
      "source": [
        "print(\"training model...\")\n",
        "history = model.fit(xr, b, batch_size = batchSize, epochs = numEpochs, verbose = True,\n",
        "                    validation_data = (xv, bv))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xv, bv, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f6a006-eaa3-4d80-84eb-821d6958798a",
        "id": "aHyBS7PKEn0T"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "764/764 - 3s - loss: 5.7959 - accuracy: 0.1156 - 3s/epoch - 4ms/step\n",
            "Accuracy: 11.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RQ1-RQ2**"
      ],
      "metadata": {
        "id": "vfXq6_rvXbZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this research question we want to see if the model is going to memorize secrets and we want to compute the average exposure. For that we will insert the same secret different number of times and average the value of exposure and report that for average exposure of the model. "
      ],
      "metadata": {
        "id": "NplsvW3fXwL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)"
      ],
      "metadata": {
        "id": "jNnvKqj3j242"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032ac9a2-cd5f-4de9-f8f3-abb00e1bb260",
        "id": "Z_gNNVOij242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+---------------------------------------+\n",
            "| THANK YOU FOR USING THE SECRET SHARER |\n",
            "+---------------------------------------+\n",
            "\n",
            " True secrets inserted: 1\n",
            " False secrets inserted: 2\n",
            " Randomness space: 100\n",
            " Training epochs: 5\n",
            " Batch size: 256\n",
            " Secret text: 'my permanent code is 73 04'\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "preparing data...\n"
          ]
        }
      ],
      "source": [
        "# 0. EXPERIMENTAL SETUP ====================================\n",
        "\n",
        "# how many copies of the secret do we insert?\n",
        "numTrueSecrets = 1\n",
        "# how many 'noisy' secrets do we insert?\n",
        "numFalseSecrets = 2\n",
        "# how many ticks are on our lock?\n",
        "numDistinctValues = 100\n",
        "# how long should we train the model?\n",
        "numEpochs = 5\n",
        "batchSize = 256\n",
        "\n",
        "# what form should the secret take?\n",
        "secretPref = \"my permanent code is \"\n",
        "seqLength = len(secretPref.split())\n",
        "gramSize = seqLength + 1\n",
        "\n",
        "# randomness space\n",
        "secretLength = 2\n",
        "bigR = numDistinctValues ** secretLength\n",
        "\n",
        "# generate a random secret\n",
        "secretText = generateSecret(secretLength, numDistinctValues)\n",
        "insertedSecret = secretPref + secretText\n",
        "\n",
        "print(\"\\n+---------------------------------------+\")\n",
        "print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
        "print(\"+---------------------------------------+\\n\")\n",
        "print(\" True secrets inserted:\", numTrueSecrets)\n",
        "print(\" False secrets inserted:\", numFalseSecrets)\n",
        "print(\" Randomness space:\", numDistinctValues)\n",
        "print(\" Training epochs:\", numEpochs)\n",
        "print(\" Batch size:\", batchSize)\n",
        "print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"\\npreparing data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rootId = len(dataRaw)"
      ],
      "metadata": {
        "id": "pjK3fdL40k9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTa_6LD3j242"
      },
      "outputs": [],
      "source": [
        "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
        "#d here is all possible secrets\n",
        "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
        "# get some noise from these fake secret to add to training\n",
        "\n",
        "if numFalseSecrets > 0:\n",
        "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
        "    noiseDF = pd.DataFrame(noise)\n",
        "\n",
        "testSecret = pd.DataFrame(d);\n",
        "#test data has all possible secrets in it now\n",
        "dataRawT = dataRawT.append(d)\n",
        "#data for dct\n",
        "dataRawdct = dataRaw.append(d)\n",
        "\n",
        "d = []\n",
        "# several in training data\n",
        "for i in range(numTrueSecrets):\n",
        "    d.append({'id' : rootId,\n",
        "              'text' : insertedSecret,\n",
        "              'noPunc' : insertedSecret,\n",
        "              'splchk' : insertedSecret})\n",
        "    rootId += 1\n",
        "#truesecrets add in train data\n",
        "trainSecret = pd.DataFrame(d)\n",
        "dataRawR = dataRawR.append(d)\n",
        "#also the noise is added to train set\n",
        "if numFalseSecrets > 0:\n",
        "    dataRawR = dataRawR.append(noiseDF)\n",
        "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
        "\n",
        "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
        "\n",
        "d = []\n",
        "gid = 0\n",
        "for i in range(len(dataRawR)):\n",
        "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsR = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawV)):\n",
        "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsV = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawT)):\n",
        "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsT = pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV3kYLFPj243"
      },
      "outputs": [],
      "source": [
        "# word IDs\n",
        "#dct from dataRaw\n",
        "dct = dict()\n",
        "# word frequencies\n",
        "dctFreq = dict()\n",
        "did = 0\n",
        "for i in range(len(dataRawdct)):\n",
        "    s = dataRawdct.splchk.iloc[i].split()\n",
        "    for w in s:\n",
        "        if w not in dct:\n",
        "            dct[w] = did\n",
        "            did += 1\n",
        "            dctFreq[w] = 1\n",
        "        else:\n",
        "            dctFreq[w] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDgJLLDoj243"
      },
      "outputs": [],
      "source": [
        "dctNoSingle = dict()\n",
        "did = 0\n",
        "for w in list(dct.keys()):\n",
        "    if dctFreq[w] !=1:\n",
        "        dctNoSingle[w] = did\n",
        "        did += 1\n",
        "        \n",
        "dct = dctNoSingle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mph6ev3nj243"
      },
      "outputs": [],
      "source": [
        "def noSingleUseWords(tup):\n",
        "    for w in tup:\n",
        "        if w not in dct:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "dataGramsR = dataGramsR[dataGramsR['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsT = dataGramsT[dataGramsT['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsV = dataGramsV[dataGramsV['data'].apply(noSingleUseWords) == True]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlDEhyV3j243"
      },
      "outputs": [],
      "source": [
        "def encodeText(tup):\n",
        "    code = [None] * len(tup)\n",
        "    for i in range(len(tup)):\n",
        "        code[i] = dct[tup[i]]  \n",
        "    return tuple(code)\n",
        "\n",
        "dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n",
        "dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
        "dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4STg8tCZj244"
      },
      "outputs": [],
      "source": [
        "dataGramsR['x'] = dataGramsR['codes'].apply(dataSplit)\n",
        "dataGramsR['y'] = dataGramsR['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
        "dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsV['x'] = dataGramsV['codes'].apply(dataSplit)\n",
        "dataGramsV['y'] = dataGramsV['codes'].apply(labelSplit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cTXSwuDj244"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "xr = np.zeros((len(dataGramsR), seqLength), dtype = int) \n",
        "yr = np.zeros((len(dataGramsR)), dtype = int)\n",
        "for i in range(len(dataGramsR)):\n",
        "    for j in range(len(dataGramsR.x.iloc[i])):\n",
        "        xr[i][j] = dataGramsR.x.iloc[i][j]\n",
        "    yr[i] = dataGramsR.y.iloc[i]\n",
        "\n",
        "# validation\n",
        "xv = np.zeros((len(dataGramsV), seqLength), dtype = int)\n",
        "yv = np.zeros((len(dataGramsV)), dtype = int)    \n",
        "for i in range(len(dataGramsV)):\n",
        "    for j in range(len(dataGramsV.x.iloc[i])):\n",
        "        xv[i][j] = dataGramsV.x.iloc[i][j]\n",
        "    yv[i] = dataGramsV.y.iloc[i]\n",
        "    \n",
        "# testing\n",
        "xt = np.zeros((len(dataGramsT), seqLength), dtype = int)\n",
        "yt = np.zeros((len(dataGramsT)), dtype = int)\n",
        "for i in range(len(dataGramsT)):\n",
        "    for j in range(len(dataGramsT.x.iloc[i])):\n",
        "        xt[i][j] = dataGramsT.x.iloc[i][j]\n",
        "    yt[i] = dataGramsT.y.iloc[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to add numbers that are not in dictionary to the dictionary\n",
        "counter = len(dct)\n",
        "for i in range(150):\n",
        "  if str(i) not in dct:\n",
        "    counter += 1\n",
        "    dct[str(i)] = counter"
      ],
      "metadata": {
        "id": "9RS2LtXexyjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(dct)\n",
        "vocabSize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54fdb3a1-1854-4668-d1fc-fffea035620c",
        "id": "0_5sZRTlj245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8597"
            ]
          },
          "metadata": {},
          "execution_count": 1575
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkEsJ2yXj245"
      },
      "outputs": [],
      "source": [
        "# 5.1 ONE-HOT ENCODE LABEL DATA ----------------------------\n",
        "# training\n",
        "\n",
        "\n",
        "b = np.zeros((len(yr), vocabSize))\n",
        "b[np.arange(len(yr)), yr] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbXIgSsIj245"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "\n",
        "\n",
        "bv = np.zeros((len(yv), vocabSize))\n",
        "bv[np.arange(len(yv)), yv] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5TITD0bj245"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a57a48e1-0cef-4473-fce5-eaac1c6f39f0",
        "id": "LzthD8Kwj246"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1579
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC89HWs8j246"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL1SgEH6j247"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYd1Xu_zj247"
      },
      "outputs": [],
      "source": [
        "# 5.2 COMPILE MODEL ----------------------------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabSize, seqLength, input_length = seqLength))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocabSize, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbbmuHmZj247"
      },
      "outputs": [],
      "source": [
        "#plot_model(model, to_file='LSTM_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04e225d-e17a-453b-d19d-2b31ab01ad12",
        "id": "vEXaVKf7j247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model...\n",
            "Epoch 1/5\n",
            "382/382 [==============================] - 10s 18ms/step - loss: 6.9515 - accuracy: 0.0368 - val_loss: 6.6799 - val_accuracy: 0.0399\n",
            "Epoch 2/5\n",
            "382/382 [==============================] - 4s 12ms/step - loss: 6.5955 - accuracy: 0.0431 - val_loss: 6.5922 - val_accuracy: 0.0518\n",
            "Epoch 3/5\n",
            "382/382 [==============================] - 5s 12ms/step - loss: 6.3749 - accuracy: 0.0568 - val_loss: 6.2545 - val_accuracy: 0.0784\n",
            "Epoch 4/5\n",
            "382/382 [==============================] - 4s 12ms/step - loss: 6.0004 - accuracy: 0.0874 - val_loss: 5.9969 - val_accuracy: 0.1020\n",
            "Epoch 5/5\n",
            "382/382 [==============================] - 5s 12ms/step - loss: 5.7095 - accuracy: 0.1090 - val_loss: 5.8465 - val_accuracy: 0.1220\n"
          ]
        }
      ],
      "source": [
        "print(\"training model...\")\n",
        "history = model.fit(xr, b, batch_size = batchSize, epochs = numEpochs, verbose = True,\n",
        "                    validation_data = (xv, bv))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xv, bv, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0CJvldlb0dg",
        "outputId": "4032c0db-4dc8-406d-a86f-62baaa5dd808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "785/785 - 3s - loss: 5.8465 - accuracy: 0.1220 - 3s/epoch - 4ms/step\n",
            "Accuracy: 12.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1e0975-1ad1-4e8f-8f38-114667d5f5ef",
        "id": "uIhgvCv5j247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RQ1-1-2sec.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 1586
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'RQ1-1-2sec.sav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RQ3**"
      ],
      "metadata": {
        "id": "Voq6qIZy29i6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this research question we want to see rare secrets and secrets that has been exposed to model more than one time make difference in exposure metric"
      ],
      "metadata": {
        "id": "l_tTUc4g29i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)"
      ],
      "metadata": {
        "id": "9UREtL8V29i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba178c37-1fbb-410d-d2e2-517b2f30f4b5",
        "id": "KYnUuzB829i8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+---------------------------------------+\n",
            "| THANK YOU FOR USING THE SECRET SHARER |\n",
            "+---------------------------------------+\n",
            "\n",
            " True secrets inserted: 20\n",
            " False secrets inserted: 2\n",
            " Randomness space: 100\n",
            " Training epochs: 7\n",
            " Batch size: 256\n",
            " Secret text: 'my permanent code is 73 04'\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "preparing data...\n"
          ]
        }
      ],
      "source": [
        "# 0. EXPERIMENTAL SETUP ====================================\n",
        "\n",
        "# how many copies of the secret do we insert?\n",
        "numTrueSecrets = 20\n",
        "# how many 'noisy' secrets do we insert?\n",
        "numFalseSecrets = 2\n",
        "# how many ticks are on our lock?\n",
        "numDistinctValues = 100\n",
        "# how long should we train the model?\n",
        "numEpochs = 7\n",
        "batchSize = 256\n",
        "\n",
        "# what form should the secret take?\n",
        "secretPref = \"my permanent code is \"\n",
        "seqLength = len(secretPref.split())\n",
        "gramSize = seqLength + 1\n",
        "\n",
        "# randomness space\n",
        "secretLength = 2\n",
        "bigR = numDistinctValues ** secretLength\n",
        "\n",
        "# generate a random secret\n",
        "secretText = generateSecret(secretLength, numDistinctValues)\n",
        "insertedSecret = secretPref + secretText\n",
        "\n",
        "print(\"\\n+---------------------------------------+\")\n",
        "print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
        "print(\"+---------------------------------------+\\n\")\n",
        "print(\" True secrets inserted:\", numTrueSecrets)\n",
        "print(\" False secrets inserted:\", numFalseSecrets)\n",
        "print(\" Randomness space:\", numDistinctValues)\n",
        "print(\" Training epochs:\", numEpochs)\n",
        "print(\" Batch size:\", batchSize)\n",
        "print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"\\npreparing data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82dKKkHW29i9"
      },
      "outputs": [],
      "source": [
        "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
        "#d here is all possible secrets\n",
        "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
        "# get some noise from these fake secret to add to training\n",
        "\n",
        "if numFalseSecrets > 0:\n",
        "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
        "    noiseDF = pd.DataFrame(noise)\n",
        "\n",
        "testSecret = pd.DataFrame(d);\n",
        "#test data has all possible secrets in it now\n",
        "dataRawT = dataRawT.append(d)\n",
        "#data for dct\n",
        "dataRawdct = dataRaw.append(d)\n",
        "\n",
        "d = []\n",
        "# several in training data\n",
        "for i in range(numTrueSecrets):\n",
        "    d.append({'id' : rootId,\n",
        "              'text' : insertedSecret,\n",
        "              'noPunc' : insertedSecret,\n",
        "              'splchk' : insertedSecret})\n",
        "    rootId += 1\n",
        "#truesecrets add in train data\n",
        "trainSecret = pd.DataFrame(d)\n",
        "dataRawR = dataRawR.append(d)\n",
        "#also the noise is added to train set\n",
        "if numFalseSecrets > 0:\n",
        "    dataRawR = dataRawR.append(noiseDF)\n",
        "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
        "\n",
        "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
        "\n",
        "d = []\n",
        "gid = 0\n",
        "for i in range(len(dataRawR)):\n",
        "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsR = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawV)):\n",
        "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsV = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawT)):\n",
        "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsT = pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN4oaj5V29i9"
      },
      "outputs": [],
      "source": [
        "# word IDs\n",
        "#dct from dataRaw\n",
        "dct = dict()\n",
        "# word frequencies\n",
        "dctFreq = dict()\n",
        "did = 0\n",
        "for i in range(len(dataRawdct)):\n",
        "    s = dataRawdct.splchk.iloc[i].split()\n",
        "    for w in s:\n",
        "        if w not in dct:\n",
        "            dct[w] = did\n",
        "            did += 1\n",
        "            dctFreq[w] = 1\n",
        "        else:\n",
        "            dctFreq[w] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roTdHsPN29i-"
      },
      "outputs": [],
      "source": [
        "dctNoSingle = dict()\n",
        "did = 0\n",
        "for w in list(dct.keys()):\n",
        "    if dctFreq[w] !=1:\n",
        "        dctNoSingle[w] = did\n",
        "        did += 1\n",
        "        \n",
        "dct = dctNoSingle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIqhlRXf29i-"
      },
      "outputs": [],
      "source": [
        "def noSingleUseWords(tup):\n",
        "    for w in tup:\n",
        "        if w not in dct:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "dataGramsR = dataGramsR[dataGramsR['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsT = dataGramsT[dataGramsT['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsV = dataGramsV[dataGramsV['data'].apply(noSingleUseWords) == True]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36KY__rp29i_"
      },
      "outputs": [],
      "source": [
        "def encodeText(tup):\n",
        "    code = [None] * len(tup)\n",
        "    for i in range(len(tup)):\n",
        "        code[i] = dct[tup[i]]  \n",
        "    return tuple(code)\n",
        "\n",
        "dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n",
        "dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
        "dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkHg-u1t29i_"
      },
      "outputs": [],
      "source": [
        "dataGramsR['x'] = dataGramsR['codes'].apply(dataSplit)\n",
        "dataGramsR['y'] = dataGramsR['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
        "dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsV['x'] = dataGramsV['codes'].apply(dataSplit)\n",
        "dataGramsV['y'] = dataGramsV['codes'].apply(labelSplit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwBHJqrI29i_"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "xr = np.zeros((len(dataGramsR), seqLength), dtype = int) \n",
        "yr = np.zeros((len(dataGramsR)), dtype = int)\n",
        "for i in range(len(dataGramsR)):\n",
        "    for j in range(len(dataGramsR.x.iloc[i])):\n",
        "        xr[i][j] = dataGramsR.x.iloc[i][j]\n",
        "    yr[i] = dataGramsR.y.iloc[i]\n",
        "\n",
        "# validation\n",
        "xv = np.zeros((len(dataGramsV), seqLength), dtype = int)\n",
        "yv = np.zeros((len(dataGramsV)), dtype = int)    \n",
        "for i in range(len(dataGramsV)):\n",
        "    for j in range(len(dataGramsV.x.iloc[i])):\n",
        "        xv[i][j] = dataGramsV.x.iloc[i][j]\n",
        "    yv[i] = dataGramsV.y.iloc[i]\n",
        "    \n",
        "# testing\n",
        "xt = np.zeros((len(dataGramsT), seqLength), dtype = int)\n",
        "yt = np.zeros((len(dataGramsT)), dtype = int)\n",
        "for i in range(len(dataGramsT)):\n",
        "    for j in range(len(dataGramsT.x.iloc[i])):\n",
        "        xt[i][j] = dataGramsT.x.iloc[i][j]\n",
        "    yt[i] = dataGramsT.y.iloc[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to add numbers that are not in dictionary to the dictionary\n",
        "counter = len(dct)\n",
        "for i in range(150):\n",
        "  if str(i) not in dct:\n",
        "    counter += 1\n",
        "    dct[str(i)] = counter"
      ],
      "metadata": {
        "id": "yHrw3DrM29jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(dct)\n",
        "vocabSize"
      ],
      "metadata": {
        "id": "l_XiV8ML29jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvEqxoKy29jA"
      },
      "outputs": [],
      "source": [
        "# 5.1 ONE-HOT ENCODE LABEL DATA ----------------------------\n",
        "# training\n",
        "\n",
        "\n",
        "b = np.zeros((len(yr), vocabSize))\n",
        "b[np.arange(len(yr)), yr] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dQEbUpM29jB"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "\n",
        "\n",
        "bv = np.zeros((len(yv), vocabSize))\n",
        "bv[np.arange(len(yv)), yv] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htrKDrng29jB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lllrmqOH29jB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECjWz2Tf29jC"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYumbASl29jC"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN4jZI0629jC"
      },
      "outputs": [],
      "source": [
        "# 5.2 COMPILE MODEL ----------------------------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabSize, seqLength, input_length = seqLength))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocabSize, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y7UPehg29jD"
      },
      "outputs": [],
      "source": [
        "#plot_model(model, to_file='LSTM_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y5nBt2T29jD"
      },
      "outputs": [],
      "source": [
        "print(\"training model...\")\n",
        "history = model.fit(xr, b, batch_size = batchSize, epochs = numEpochs, verbose = True,\n",
        "                    validation_data = (xv, bv))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xv, bv, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "vnR2oPmP29jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27Ilb6dd29jE"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'RQ3-20sec.sav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RQ5-Glove representation**"
      ],
      "metadata": {
        "id": "8kA5i-OsM8Ny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this research question we want to compare different representations, one-hot encoding is defult, then we have fasttext, gloves and word2vec "
      ],
      "metadata": {
        "id": "s5dDKFeaM8Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)"
      ],
      "metadata": {
        "id": "-8RSKBoGM8Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to change number of times we insert secrets - we iterate between 1, 10, 70, 150, 500, 1000. And for each we run five times to find the average exposure."
      ],
      "metadata": {
        "id": "kDVgXVQmM8Nz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c716fa-9a2f-4d4a-b48b-31fb11f5d0ad",
        "id": "J8oxKTLEM8Nz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+---------------------------------------+\n",
            "| THANK YOU FOR USING THE SECRET SHARER |\n",
            "+---------------------------------------+\n",
            "\n",
            " True secrets inserted: 10\n",
            " False secrets inserted: 2\n",
            " Randomness space: 100\n",
            " Training epochs: 7\n",
            " Batch size: 256\n",
            " Secret text: 'my permanent code is 73 04'\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "preparing data...\n"
          ]
        }
      ],
      "source": [
        "# 0. EXPERIMENTAL SETUP ====================================\n",
        "\n",
        "# how many copies of the secret do we insert?\n",
        "numTrueSecrets = 10\n",
        "# how many 'noisy' secrets do we insert?\n",
        "numFalseSecrets = 2\n",
        "# how many ticks are on our lock?\n",
        "numDistinctValues = 100\n",
        "# how long should we train the model?\n",
        "numEpochs = 7\n",
        "batchSize = 256\n",
        "\n",
        "# what form should the secret take?\n",
        "secretPref = \"my permanent code is \"\n",
        "seqLength = len(secretPref.split())\n",
        "gramSize = seqLength + 1\n",
        "\n",
        "# randomness space\n",
        "secretLength = 2\n",
        "bigR = numDistinctValues ** secretLength\n",
        "\n",
        "# generate a random secret\n",
        "secretText = generateSecret(secretLength, numDistinctValues)\n",
        "insertedSecret = secretPref + secretText\n",
        "\n",
        "print(\"\\n+---------------------------------------+\")\n",
        "print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
        "print(\"+---------------------------------------+\\n\")\n",
        "print(\" True secrets inserted:\", numTrueSecrets)\n",
        "print(\" False secrets inserted:\", numFalseSecrets)\n",
        "print(\" Randomness space:\", numDistinctValues)\n",
        "print(\" Training epochs:\", numEpochs)\n",
        "print(\" Batch size:\", batchSize)\n",
        "print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"\\npreparing data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6FreURfM8N0"
      },
      "outputs": [],
      "source": [
        "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
        "#d here is all possible secrets\n",
        "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
        "# get some noise from these fake secret to add to training\n",
        "\n",
        "if numFalseSecrets > 0:\n",
        "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
        "    noiseDF = pd.DataFrame(noise)\n",
        "\n",
        "testSecret = pd.DataFrame(d);\n",
        "#test data has all possible secrets in it now\n",
        "dataRawT = dataRawT.append(d)\n",
        "#data for dct\n",
        "dataRawdct = dataRaw.append(d)\n",
        "\n",
        "d = []\n",
        "# several in training data\n",
        "for i in range(numTrueSecrets):\n",
        "    d.append({'id' : rootId,\n",
        "              'text' : insertedSecret,\n",
        "              'noPunc' : insertedSecret,\n",
        "              'splchk' : insertedSecret})\n",
        "    rootId += 1\n",
        "#truesecrets add in train data\n",
        "trainSecret = pd.DataFrame(d)\n",
        "dataRawR = dataRawR.append(d)\n",
        "#also the noise is added to train set\n",
        "if numFalseSecrets > 0:\n",
        "    dataRawR = dataRawR.append(noiseDF)\n",
        "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
        "\n",
        "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
        "\n",
        "d = []\n",
        "gid = 0\n",
        "for i in range(len(dataRawR)):\n",
        "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsR = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawV)):\n",
        "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsV = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawT)):\n",
        "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsT = pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9bdynMUM8N0"
      },
      "outputs": [],
      "source": [
        "# word IDs\n",
        "#dct from dataRaw\n",
        "dct = dict()\n",
        "# word frequencies\n",
        "dctFreq = dict()\n",
        "did = 0\n",
        "for i in range(len(dataRawdct)):\n",
        "    s = dataRawdct.splchk.iloc[i].split()\n",
        "    for w in s:\n",
        "        if w not in dct:\n",
        "            dct[w] = did\n",
        "            did += 1\n",
        "            dctFreq[w] = 1\n",
        "        else:\n",
        "            dctFreq[w] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8DLoNmcM8N0"
      },
      "outputs": [],
      "source": [
        "dctNoSingle = dict()\n",
        "did = 0\n",
        "for w in list(dct.keys()):\n",
        "    if dctFreq[w] !=1:\n",
        "        dctNoSingle[w] = did\n",
        "        did += 1\n",
        "        \n",
        "dct = dctNoSingle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twjC7mWNM8N1"
      },
      "outputs": [],
      "source": [
        "def noSingleUseWords(tup):\n",
        "    for w in tup:\n",
        "        if w not in dct:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "dataGramsR = dataGramsR[dataGramsR['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsT = dataGramsT[dataGramsT['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsV = dataGramsV[dataGramsV['data'].apply(noSingleUseWords) == True]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLomwFBTM8N1"
      },
      "outputs": [],
      "source": [
        "def encodeText(tup):\n",
        "    code = [None] * len(tup)\n",
        "    for i in range(len(tup)):\n",
        "        code[i] = dct[tup[i]]  \n",
        "    return tuple(code)\n",
        "\n",
        "dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n",
        "dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
        "dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSM9JrdtM8N1"
      },
      "outputs": [],
      "source": [
        "dataGramsR['x'] = dataGramsR['codes'].apply(dataSplit)\n",
        "dataGramsR['y'] = dataGramsR['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
        "dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsV['x'] = dataGramsV['codes'].apply(dataSplit)\n",
        "dataGramsV['y'] = dataGramsV['codes'].apply(labelSplit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbe1o3CHM8N1"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "xr = np.zeros((len(dataGramsR), seqLength), dtype = int) \n",
        "yr = np.zeros((len(dataGramsR)), dtype = int)\n",
        "for i in range(len(dataGramsR)):\n",
        "    for j in range(len(dataGramsR.x.iloc[i])):\n",
        "        xr[i][j] = dataGramsR.x.iloc[i][j]\n",
        "    yr[i] = dataGramsR.y.iloc[i]\n",
        "\n",
        "# validation\n",
        "xv = np.zeros((len(dataGramsV), seqLength), dtype = int)\n",
        "yv = np.zeros((len(dataGramsV)), dtype = int)    \n",
        "for i in range(len(dataGramsV)):\n",
        "    for j in range(len(dataGramsV.x.iloc[i])):\n",
        "        xv[i][j] = dataGramsV.x.iloc[i][j]\n",
        "    yv[i] = dataGramsV.y.iloc[i]\n",
        "    \n",
        "# testing\n",
        "xt = np.zeros((len(dataGramsT), seqLength), dtype = int)\n",
        "yt = np.zeros((len(dataGramsT)), dtype = int)\n",
        "for i in range(len(dataGramsT)):\n",
        "    for j in range(len(dataGramsT.x.iloc[i])):\n",
        "        xt[i][j] = dataGramsT.x.iloc[i][j]\n",
        "    yt[i] = dataGramsT.y.iloc[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to add numbers that are not in dictionary to the dictionary\n",
        "counter = len(dct)\n",
        "for i in range(150):\n",
        "  if str(i) not in dct:\n",
        "    counter += 1\n",
        "    dct[str(i)] = counter"
      ],
      "metadata": {
        "id": "nqDwhdAbM8N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(dct)\n",
        "vocabSize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f0601a-9c4a-46d3-baa9-02059d9e8001",
        "id": "gDEMhIY-M8N2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9558"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PorHytUsM8N2"
      },
      "outputs": [],
      "source": [
        "# 5.1 ONE-HOT ENCODE LABEL DATA ----------------------------\n",
        "# training\n",
        "\n",
        "\n",
        "b = np.zeros((len(yr), vocabSize))\n",
        "b[np.arange(len(yr)), yr] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX4LBKEuM8N2"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "\n",
        "\n",
        "bv = np.zeros((len(yv), vocabSize))\n",
        "bv[np.arange(len(yv)), yv] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "metadata": {
        "id": "-dRIwGlXwqFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28abea3-24b4-4eaf-cdb3-e82dc7594ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 06:05:36--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-12-02 06:05:37--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-12-02 06:05:38--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.2’\n",
            "\n",
            "glove.6B.zip.2      100%[===================>] 822.24M  2.17MB/s    in 6m 16s  \n",
            "\n",
            "2022-12-02 06:11:55 (2.19 MB/s) - ‘glove.6B.zip.2’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.100d.txt       y\n",
            "\n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: glove.6B.200d.txt       y\n",
            "\n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: glove.6B.300d.txt       y\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "metadata": {
        "id": "tfVrDLOUOz_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connect embeding to previous dct\n",
        "embedding_matrix = np.zeros((vocabSize, 300))\n",
        "for word, index in dct.items():\n",
        "    if index > vocabSize - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[index] = embedding_vector"
      ],
      "metadata": {
        "id": "0N1yjI_kO1Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFyG9lxsM8N2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e915b8c2-4a8a-4461-9f0f-062cbdf44794",
        "id": "msWLrmMFM8N2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR3zGTIfM8N3"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSt5TfboM8N3"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym-LpXevM8N3"
      },
      "outputs": [],
      "source": [
        "# 5.2 COMPILE MODEL ----------------------------------------\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocabSize, seqLength, input_length = seqLength))\n",
        "model.add(Embedding(vocabSize, 300 ,input_length=seqLength, name=\"embeddinglayer\", weights=[embedding_matrix], trainable=False))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocabSize, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY7pKdCGM8N3"
      },
      "outputs": [],
      "source": [
        "#plot_model(model, to_file='LSTM_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017dc069-24f4-4342-c01a-09588b2ca9a4",
        "id": "noB6tApgM8N3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model...\n",
            "Epoch 1/7\n",
            "419/419 [==============================] - 11s 19ms/step - loss: 6.8688 - accuracy: 0.0395 - val_loss: 6.6620 - val_accuracy: 0.0431\n",
            "Epoch 2/7\n",
            "419/419 [==============================] - 6s 14ms/step - loss: 6.5091 - accuracy: 0.0441 - val_loss: 6.4179 - val_accuracy: 0.0509\n",
            "Epoch 3/7\n",
            "419/419 [==============================] - 5s 13ms/step - loss: 6.2133 - accuracy: 0.0583 - val_loss: 6.2504 - val_accuracy: 0.0671\n",
            "Epoch 4/7\n",
            "419/419 [==============================] - 5s 12ms/step - loss: 5.9799 - accuracy: 0.0743 - val_loss: 6.1615 - val_accuracy: 0.0801\n",
            "Epoch 5/7\n",
            "419/419 [==============================] - 5s 12ms/step - loss: 5.7891 - accuracy: 0.0859 - val_loss: 6.0849 - val_accuracy: 0.0860\n",
            "Epoch 6/7\n",
            "419/419 [==============================] - 5s 12ms/step - loss: 5.6177 - accuracy: 0.0949 - val_loss: 6.0535 - val_accuracy: 0.0919\n",
            "Epoch 7/7\n",
            "419/419 [==============================] - 5s 12ms/step - loss: 5.4567 - accuracy: 0.1020 - val_loss: 6.0489 - val_accuracy: 0.0965\n"
          ]
        }
      ],
      "source": [
        "print(\"training model...\")\n",
        "history = model.fit(xr, b, batch_size = batchSize, epochs = numEpochs, verbose = True,\n",
        "                    validation_data = (xv, bv))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xv, bv, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "3KbDaSSRM8N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908e82fa-e6fe-45db-b86d-96755094c72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "860/860 - 4s - loss: 6.0489 - accuracy: 0.0965 - 4s/epoch - 4ms/step\n",
            "Accuracy: 9.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8af67e0-2bfb-4e4e-954f-ff252aa6042a",
        "id": "Kd2FwFwvM8N4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RQ5-glove rep-3.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'RQ5-glove rep-3.sav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RQ5-fasttext representation**"
      ],
      "metadata": {
        "id": "hHsWayqpSrJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this research question we want to compare different representations, one-hot encoding is defult, then we have fasttext, gloves and word2vec "
      ],
      "metadata": {
        "id": "OwIo3c0QSrJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)"
      ],
      "metadata": {
        "id": "etxVyNdZSrJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "861e68ec-59c4-4f41-840c-ba1bb175ecb0",
        "id": "GH0rSUsoSrJV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+---------------------------------------+\n",
            "| THANK YOU FOR USING THE SECRET SHARER |\n",
            "+---------------------------------------+\n",
            "\n",
            " True secrets inserted: 10\n",
            " False secrets inserted: 2\n",
            " Randomness space: 100\n",
            " Training epochs: 7\n",
            " Batch size: 256\n",
            " Secret text: 'my permanent code is 73 04'\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "preparing data...\n"
          ]
        }
      ],
      "source": [
        "# 0. EXPERIMENTAL SETUP ====================================\n",
        "\n",
        "# how many copies of the secret do we insert?\n",
        "numTrueSecrets = 10\n",
        "# how many 'noisy' secrets do we insert?\n",
        "numFalseSecrets = 2\n",
        "# how many ticks are on our lock?\n",
        "numDistinctValues = 100\n",
        "# how long should we train the model?\n",
        "numEpochs = 7\n",
        "batchSize = 256\n",
        "\n",
        "# what form should the secret take?\n",
        "secretPref = \"my permanent code is \"\n",
        "seqLength = len(secretPref.split())\n",
        "gramSize = seqLength + 1\n",
        "\n",
        "# randomness space\n",
        "secretLength = 2\n",
        "bigR = numDistinctValues ** secretLength\n",
        "\n",
        "# generate a random secret\n",
        "secretText = generateSecret(secretLength, numDistinctValues)\n",
        "insertedSecret = secretPref + secretText\n",
        "\n",
        "print(\"\\n+---------------------------------------+\")\n",
        "print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
        "print(\"+---------------------------------------+\\n\")\n",
        "print(\" True secrets inserted:\", numTrueSecrets)\n",
        "print(\" False secrets inserted:\", numFalseSecrets)\n",
        "print(\" Randomness space:\", numDistinctValues)\n",
        "print(\" Training epochs:\", numEpochs)\n",
        "print(\" Batch size:\", batchSize)\n",
        "print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"\\npreparing data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMamZMffSrJW"
      },
      "outputs": [],
      "source": [
        "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
        "#d here is all possible secrets\n",
        "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
        "# get some noise from these fake secret to add to training\n",
        "\n",
        "if numFalseSecrets > 0:\n",
        "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
        "    noiseDF = pd.DataFrame(noise)\n",
        "\n",
        "testSecret = pd.DataFrame(d);\n",
        "#test data has all possible secrets in it now\n",
        "dataRawT = dataRawT.append(d)\n",
        "#data for dct\n",
        "dataRawdct = dataRaw.append(d)\n",
        "\n",
        "d = []\n",
        "# several in training data\n",
        "for i in range(numTrueSecrets):\n",
        "    d.append({'id' : rootId,\n",
        "              'text' : insertedSecret,\n",
        "              'noPunc' : insertedSecret,\n",
        "              'splchk' : insertedSecret})\n",
        "    rootId += 1\n",
        "#truesecrets add in train data\n",
        "trainSecret = pd.DataFrame(d)\n",
        "dataRawR = dataRawR.append(d)\n",
        "#also the noise is added to train set\n",
        "if numFalseSecrets > 0:\n",
        "    dataRawR = dataRawR.append(noiseDF)\n",
        "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
        "\n",
        "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
        "\n",
        "d = []\n",
        "gid = 0\n",
        "for i in range(len(dataRawR)):\n",
        "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsR = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawV)):\n",
        "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsV = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawT)):\n",
        "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsT = pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWZyFovWSrJW"
      },
      "outputs": [],
      "source": [
        "# word IDs\n",
        "#dct from dataRaw\n",
        "dct = dict()\n",
        "# word frequencies\n",
        "dctFreq = dict()\n",
        "did = 0\n",
        "for i in range(len(dataRawdct)):\n",
        "    s = dataRawdct.splchk.iloc[i].split()\n",
        "    for w in s:\n",
        "        if w not in dct:\n",
        "            dct[w] = did\n",
        "            did += 1\n",
        "            dctFreq[w] = 1\n",
        "        else:\n",
        "            dctFreq[w] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_kWNwIBSrJW"
      },
      "outputs": [],
      "source": [
        "dctNoSingle = dict()\n",
        "did = 0\n",
        "for w in list(dct.keys()):\n",
        "    if dctFreq[w] !=1:\n",
        "        dctNoSingle[w] = did\n",
        "        did += 1\n",
        "        \n",
        "dct = dctNoSingle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKkgb5QRSrJW"
      },
      "outputs": [],
      "source": [
        "def noSingleUseWords(tup):\n",
        "    for w in tup:\n",
        "        if w not in dct:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "dataGramsR = dataGramsR[dataGramsR['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsT = dataGramsT[dataGramsT['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsV = dataGramsV[dataGramsV['data'].apply(noSingleUseWords) == True]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0sVifwjSrJW"
      },
      "outputs": [],
      "source": [
        "def encodeText(tup):\n",
        "    code = [None] * len(tup)\n",
        "    for i in range(len(tup)):\n",
        "        code[i] = dct[tup[i]]  \n",
        "    return tuple(code)\n",
        "\n",
        "dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n",
        "dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
        "dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vENRvmpTSrJX"
      },
      "outputs": [],
      "source": [
        "dataGramsR['x'] = dataGramsR['codes'].apply(dataSplit)\n",
        "dataGramsR['y'] = dataGramsR['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
        "dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsV['x'] = dataGramsV['codes'].apply(dataSplit)\n",
        "dataGramsV['y'] = dataGramsV['codes'].apply(labelSplit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwJMYUNXSrJX"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "xr = np.zeros((len(dataGramsR), seqLength), dtype = int) \n",
        "yr = np.zeros((len(dataGramsR)), dtype = int)\n",
        "for i in range(len(dataGramsR)):\n",
        "    for j in range(len(dataGramsR.x.iloc[i])):\n",
        "        xr[i][j] = dataGramsR.x.iloc[i][j]\n",
        "    yr[i] = dataGramsR.y.iloc[i]\n",
        "\n",
        "# validation\n",
        "xv = np.zeros((len(dataGramsV), seqLength), dtype = int)\n",
        "yv = np.zeros((len(dataGramsV)), dtype = int)    \n",
        "for i in range(len(dataGramsV)):\n",
        "    for j in range(len(dataGramsV.x.iloc[i])):\n",
        "        xv[i][j] = dataGramsV.x.iloc[i][j]\n",
        "    yv[i] = dataGramsV.y.iloc[i]\n",
        "    \n",
        "# testing\n",
        "xt = np.zeros((len(dataGramsT), seqLength), dtype = int)\n",
        "yt = np.zeros((len(dataGramsT)), dtype = int)\n",
        "for i in range(len(dataGramsT)):\n",
        "    for j in range(len(dataGramsT.x.iloc[i])):\n",
        "        xt[i][j] = dataGramsT.x.iloc[i][j]\n",
        "    yt[i] = dataGramsT.y.iloc[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to add numbers that are not in dictionary to the dictionary\n",
        "counter = len(dct)\n",
        "for i in range(150):\n",
        "  if str(i) not in dct:\n",
        "    counter += 1\n",
        "    dct[str(i)] = counter"
      ],
      "metadata": {
        "id": "CeEGudJaSrJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(dct)\n",
        "vocabSize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6009c0c-d162-424c-d1e5-c36df8bdbd44",
        "id": "JS3J6MqYSrJX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9558"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJU2geiVSrJX"
      },
      "outputs": [],
      "source": [
        "# 5.1 ONE-HOT ENCODE LABEL DATA ----------------------------\n",
        "# training\n",
        "\n",
        "\n",
        "b = np.zeros((len(yr), vocabSize))\n",
        "b[np.arange(len(yr)), yr] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGUe1CL-SrJX"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "\n",
        "\n",
        "bv = np.zeros((len(yv), vocabSize))\n",
        "bv[np.arange(len(yv)), yv] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f321497-c9db-4a58-8888-44e168cf1766",
        "id": "p3sAe-69SrJY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 06:19:17--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip.1’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  1.75MB/s    in 3m 24s  \n",
            "\n",
            "2022-12-02 06:22:42 (3.18 MB/s) - ‘wiki-news-300d-1M.vec.zip.1’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "replace wiki-news-300d-1M.vec? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: wiki-news-300d-1M.vec   y\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/wiki-news-300d-1M.vec')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "metadata": {
        "id": "8GbQj_FISrJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connect embeding to previous dct\n",
        "embedding_matrix = np.zeros((vocabSize, 300))\n",
        "for word, index in dct.items():\n",
        "    if index > vocabSize - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[index] = embedding_vector"
      ],
      "metadata": {
        "id": "PPcqRY0pSrJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTjAA02YSrJY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "54ddcb19-3f8e-4b2b-eb5d-88d8fb02c548",
        "id": "rS16byxJSrJY"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBxz0n_ZSrJY"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOdLSrs7SrJZ"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZXtcaZaSrJZ"
      },
      "outputs": [],
      "source": [
        "# 5.2 COMPILE MODEL ----------------------------------------\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocabSize, seqLength, input_length = seqLength))\n",
        "model.add(Embedding(vocabSize, 300 ,input_length=seqLength, name=\"embeddinglayer\", weights=[embedding_matrix], trainable=False))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocabSize, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw8Q2QCiSrJZ"
      },
      "outputs": [],
      "source": [
        "#plot_model(model, to_file='LSTM_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c6fef7-45dc-4c7a-dcb9-d51506c99053",
        "id": "TKABv2O7SrJZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model...\n",
            "Epoch 1/7\n",
            "418/418 [==============================] - 11s 18ms/step - loss: 6.8903 - accuracy: 0.0397 - val_loss: 6.6882 - val_accuracy: 0.0438\n",
            "Epoch 2/7\n",
            "418/418 [==============================] - 5s 12ms/step - loss: 6.5957 - accuracy: 0.0412 - val_loss: 6.6147 - val_accuracy: 0.0443\n",
            "Epoch 3/7\n",
            "418/418 [==============================] - 5s 13ms/step - loss: 6.3906 - accuracy: 0.0480 - val_loss: 6.4073 - val_accuracy: 0.0574\n",
            "Epoch 4/7\n",
            "418/418 [==============================] - 5s 12ms/step - loss: 6.1397 - accuracy: 0.0625 - val_loss: 6.2469 - val_accuracy: 0.0728\n",
            "Epoch 5/7\n",
            "418/418 [==============================] - 5s 12ms/step - loss: 5.9313 - accuracy: 0.0782 - val_loss: 6.1569 - val_accuracy: 0.0832\n",
            "Epoch 6/7\n",
            "418/418 [==============================] - 5s 12ms/step - loss: 5.7745 - accuracy: 0.0857 - val_loss: 6.1221 - val_accuracy: 0.0866\n",
            "Epoch 7/7\n",
            "418/418 [==============================] - 5s 12ms/step - loss: 5.6386 - accuracy: 0.0919 - val_loss: 6.0985 - val_accuracy: 0.0926\n"
          ]
        }
      ],
      "source": [
        "print(\"training model...\")\n",
        "history = model.fit(xr, b, batch_size = batchSize, epochs = numEpochs, verbose = True,\n",
        "                    validation_data = (xv, bv))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xv, bv, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa13efb-cc81-472f-c956-753463fbf241",
        "id": "tocxy-tCSrJZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "852/852 - 4s - loss: 6.1152 - accuracy: 0.0901 - 4s/epoch - 4ms/step\n",
            "Accuracy: 9.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21da8c9a-3193-4222-80f1-0b1517f6100b",
        "id": "kbmFVdAESrJZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RQ5-fasttextrep-3.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'RQ5-fasttextrep-3.sav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RQ5-Word2vec representation**"
      ],
      "metadata": {
        "id": "NrPw-bGwUgY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this research question we want to compare different representations, one-hot encoding is defult, then we have fasttext, gloves and word2vec "
      ],
      "metadata": {
        "id": "5vxeiMnsUgY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)"
      ],
      "metadata": {
        "id": "hm-iMH1SUgY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c0fe15-a296-4045-e804-6cd010890013",
        "id": "nsaQu_Q2UgY5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+---------------------------------------+\n",
            "| THANK YOU FOR USING THE SECRET SHARER |\n",
            "+---------------------------------------+\n",
            "\n",
            " True secrets inserted: 10\n",
            " False secrets inserted: 2\n",
            " Randomness space: 100\n",
            " Training epochs: 7\n",
            " Batch size: 256\n",
            " Secret text: 'my permanent code is 73 04'\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "preparing data...\n"
          ]
        }
      ],
      "source": [
        "# 0. EXPERIMENTAL SETUP ====================================\n",
        "\n",
        "# how many copies of the secret do we insert?\n",
        "numTrueSecrets = 10\n",
        "# how many 'noisy' secrets do we insert?\n",
        "numFalseSecrets = 2\n",
        "# how many ticks are on our lock?\n",
        "numDistinctValues = 100\n",
        "# how long should we train the model?\n",
        "numEpochs = 7\n",
        "batchSize = 256\n",
        "\n",
        "# what form should the secret take?\n",
        "secretPref = \"my permanent code is \"\n",
        "seqLength = len(secretPref.split())\n",
        "gramSize = seqLength + 1\n",
        "\n",
        "# randomness space\n",
        "secretLength = 2\n",
        "bigR = numDistinctValues ** secretLength\n",
        "\n",
        "# generate a random secret\n",
        "secretText = generateSecret(secretLength, numDistinctValues)\n",
        "insertedSecret = secretPref + secretText\n",
        "\n",
        "print(\"\\n+---------------------------------------+\")\n",
        "print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
        "print(\"+---------------------------------------+\\n\")\n",
        "print(\" True secrets inserted:\", numTrueSecrets)\n",
        "print(\" False secrets inserted:\", numFalseSecrets)\n",
        "print(\" Randomness space:\", numDistinctValues)\n",
        "print(\" Training epochs:\", numEpochs)\n",
        "print(\" Batch size:\", batchSize)\n",
        "print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"\\npreparing data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psWxYdXvUgY5"
      },
      "outputs": [],
      "source": [
        "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
        "#d here is all possible secrets\n",
        "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
        "# get some noise from these fake secret to add to training\n",
        "\n",
        "if numFalseSecrets > 0:\n",
        "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
        "    noiseDF = pd.DataFrame(noise)\n",
        "\n",
        "testSecret = pd.DataFrame(d);\n",
        "#test data has all possible secrets in it now\n",
        "dataRawT = dataRawT.append(d)\n",
        "#data for dct\n",
        "dataRawdct = dataRaw.append(d)\n",
        "\n",
        "d = []\n",
        "# several in training data\n",
        "for i in range(numTrueSecrets):\n",
        "    d.append({'id' : rootId,\n",
        "              'text' : insertedSecret,\n",
        "              'noPunc' : insertedSecret,\n",
        "              'splchk' : insertedSecret})\n",
        "    rootId += 1\n",
        "#truesecrets add in train data\n",
        "trainSecret = pd.DataFrame(d)\n",
        "dataRawR = dataRawR.append(d)\n",
        "#also the noise is added to train set\n",
        "if numFalseSecrets > 0:\n",
        "    dataRawR = dataRawR.append(noiseDF)\n",
        "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
        "\n",
        "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
        "\n",
        "d = []\n",
        "gid = 0\n",
        "for i in range(len(dataRawR)):\n",
        "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsR = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawV)):\n",
        "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsV = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawT)):\n",
        "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsT = pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAXOtiT5UgY6"
      },
      "outputs": [],
      "source": [
        "# word IDs\n",
        "#dct from dataRaw\n",
        "dct = dict()\n",
        "# word frequencies\n",
        "dctFreq = dict()\n",
        "did = 0\n",
        "for i in range(len(dataRawdct)):\n",
        "    s = dataRawdct.splchk.iloc[i].split()\n",
        "    for w in s:\n",
        "        if w not in dct:\n",
        "            dct[w] = did\n",
        "            did += 1\n",
        "            dctFreq[w] = 1\n",
        "        else:\n",
        "            dctFreq[w] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8wy4-92UgY6"
      },
      "outputs": [],
      "source": [
        "dctNoSingle = dict()\n",
        "did = 0\n",
        "for w in list(dct.keys()):\n",
        "    if dctFreq[w] !=1:\n",
        "        dctNoSingle[w] = did\n",
        "        did += 1\n",
        "        \n",
        "dct = dctNoSingle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEmjVUTMUgY7"
      },
      "outputs": [],
      "source": [
        "def noSingleUseWords(tup):\n",
        "    for w in tup:\n",
        "        if w not in dct:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "dataGramsR = dataGramsR[dataGramsR['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsT = dataGramsT[dataGramsT['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsV = dataGramsV[dataGramsV['data'].apply(noSingleUseWords) == True]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEV5Hx7iUgY7",
        "outputId": "8939a4e8-c59f-43dc-b5bc-065117092763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-173b97ba434e>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n"
          ]
        }
      ],
      "source": [
        "def encodeText(tup):\n",
        "    code = [None] * len(tup)\n",
        "    for i in range(len(tup)):\n",
        "        code[i] = dct[tup[i]]  \n",
        "    return tuple(code)\n",
        "\n",
        "dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n",
        "dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
        "dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PmLhxTGUgY7"
      },
      "outputs": [],
      "source": [
        "dataGramsR['x'] = dataGramsR['codes'].apply(dataSplit)\n",
        "dataGramsR['y'] = dataGramsR['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
        "dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsV['x'] = dataGramsV['codes'].apply(dataSplit)\n",
        "dataGramsV['y'] = dataGramsV['codes'].apply(labelSplit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfD1OsO9UgY8"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "xr = np.zeros((len(dataGramsR), seqLength), dtype = int) \n",
        "yr = np.zeros((len(dataGramsR)), dtype = int)\n",
        "for i in range(len(dataGramsR)):\n",
        "    for j in range(len(dataGramsR.x.iloc[i])):\n",
        "        xr[i][j] = dataGramsR.x.iloc[i][j]\n",
        "    yr[i] = dataGramsR.y.iloc[i]\n",
        "\n",
        "# validation\n",
        "xv = np.zeros((len(dataGramsV), seqLength), dtype = int)\n",
        "yv = np.zeros((len(dataGramsV)), dtype = int)    \n",
        "for i in range(len(dataGramsV)):\n",
        "    for j in range(len(dataGramsV.x.iloc[i])):\n",
        "        xv[i][j] = dataGramsV.x.iloc[i][j]\n",
        "    yv[i] = dataGramsV.y.iloc[i]\n",
        "    \n",
        "# testing\n",
        "xt = np.zeros((len(dataGramsT), seqLength), dtype = int)\n",
        "yt = np.zeros((len(dataGramsT)), dtype = int)\n",
        "for i in range(len(dataGramsT)):\n",
        "    for j in range(len(dataGramsT.x.iloc[i])):\n",
        "        xt[i][j] = dataGramsT.x.iloc[i][j]\n",
        "    yt[i] = dataGramsT.y.iloc[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to add numbers that are not in dictionary to the dictionary\n",
        "counter = len(dct)\n",
        "for i in range(150):\n",
        "  if str(i) not in dct:\n",
        "    counter += 1\n",
        "    dct[str(i)] = counter"
      ],
      "metadata": {
        "id": "aju-4hW8UgY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(dct)\n",
        "vocabSize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8009a05-a2f9-43e0-e60d-6d859cd686d7",
        "id": "KHUb8derUgY8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9558"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN5AswKnUgY8"
      },
      "outputs": [],
      "source": [
        "# 5.1 ONE-HOT ENCODE LABEL DATA ----------------------------\n",
        "# training\n",
        "\n",
        "\n",
        "b = np.zeros((len(yr), vocabSize))\n",
        "b[np.arange(len(yr)), yr] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU8_f1rLUgY9"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "\n",
        "\n",
        "bv = np.zeros((len(yv), vocabSize))\n",
        "bv[np.arange(len(yv)), yv] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "metadata": {
        "id": "xAlXDOppU0PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Colab Notebooks/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "embedding_matrix = np.zeros((vocabSize, 300))\n",
        "for word, index in dct.items():\n",
        "    if index > vocabSize - 1:\n",
        "        continue\n",
        "    try:\n",
        "        embedding_vector = word_vectors[word]\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "    except KeyError:\n",
        "        embedding_matrix[index]=np.random.normal(0,np.sqrt(0.25),300)\n",
        "\n",
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BmVZ6PLVced",
        "outputId": "c99ca963-3f67-40f0-ce6f-03eefbac93a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.55777863, -0.24878716,  0.30620998, ...,  0.14174   ,\n",
              "         1.08523071, -0.60734735],\n",
              "       [ 0.0534668 ,  0.01202393, -0.00650024, ..., -0.00193787,\n",
              "         0.03222656, -0.15234375],\n",
              "       [ 0.09228516, -0.20117188,  0.06933594, ..., -0.00866699,\n",
              "         0.12890625, -0.21582031],\n",
              "       ...,\n",
              "       [ 0.47984287,  0.28908406,  0.157234  , ..., -0.00237308,\n",
              "         0.13156763, -0.40962329],\n",
              "       [-0.28840399, -0.15766007,  0.53499768, ...,  0.31022538,\n",
              "         0.37841475,  0.11110215],\n",
              "       [-1.43790269,  0.6330718 ,  0.04590014, ...,  1.47957751,\n",
              "        -0.08169154,  0.23280878]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7vfR_LkZNFE",
        "outputId": "1ef09e51-9306-4795-c710-0e023b39a92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9558, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWh9h8O-UgY-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d0ae8099-6899-447d-8010-01aed9fbee1c",
        "id": "Yqp63tU3UgY-"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isaWhGIXUgY-"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKZ_jENyUgY-"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hc2W9zG2UgY_"
      },
      "outputs": [],
      "source": [
        "# 5.2 COMPILE MODEL ----------------------------------------\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocabSize, seqLength, input_length = seqLength))\n",
        "model.add(Embedding(vocabSize, 300 ,input_length=seqLength, name=\"embeddinglayer\", weights=[embedding_matrix], trainable=False))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocabSize, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HADDSlB9UgY_"
      },
      "outputs": [],
      "source": [
        "#plot_model(model, to_file='LSTM_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f358831-208b-4321-892b-da07c8bb32f3",
        "id": "cdjcT7ymUgY_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model...\n",
            "Epoch 1/7\n",
            "417/417 [==============================] - 21s 20ms/step - loss: 6.9041 - accuracy: 0.0398 - val_loss: 6.6896 - val_accuracy: 0.0399\n",
            "Epoch 2/7\n",
            "417/417 [==============================] - 5s 12ms/step - loss: 6.5970 - accuracy: 0.0419 - val_loss: 6.5977 - val_accuracy: 0.0414\n",
            "Epoch 3/7\n",
            "417/417 [==============================] - 5s 12ms/step - loss: 6.3611 - accuracy: 0.0508 - val_loss: 6.3527 - val_accuracy: 0.0547\n",
            "Epoch 4/7\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 6.0804 - accuracy: 0.0656 - val_loss: 6.1961 - val_accuracy: 0.0700\n",
            "Epoch 5/7\n",
            "417/417 [==============================] - 5s 12ms/step - loss: 5.8764 - accuracy: 0.0784 - val_loss: 6.1212 - val_accuracy: 0.0807\n",
            "Epoch 6/7\n",
            "417/417 [==============================] - 5s 12ms/step - loss: 5.7040 - accuracy: 0.0885 - val_loss: 6.0556 - val_accuracy: 0.0875\n",
            "Epoch 7/7\n",
            "417/417 [==============================] - 5s 12ms/step - loss: 5.5458 - accuracy: 0.0965 - val_loss: 6.0462 - val_accuracy: 0.0922\n"
          ]
        }
      ],
      "source": [
        "print(\"training model...\")\n",
        "history = model.fit(xr, b, batch_size = batchSize, epochs = numEpochs, verbose = True,\n",
        "                    validation_data = (xv, bv))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xv, bv, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9915c75-e9c5-442e-dac2-3ade75154762",
        "id": "RyOnTI3NUgY_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "852/852 - 4s - loss: 6.0462 - accuracy: 0.0922 - 4s/epoch - 4ms/step\n",
            "Accuracy: 9.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382bbc96-17df-4e71-fdc2-a3a393b86511",
        "id": "_hbw8o2eUgY_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RQ5-word2vec-3.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'RQ5-word2vec-3.sav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RQ6**"
      ],
      "metadata": {
        "id": "V-PmM7AsBotz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this research question we want to see if different length prefixes make difference in the exposure metric\n",
        "\n",
        "So we only change prefixes. "
      ],
      "metadata": {
        "id": "QY_8WLyVBotz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)"
      ],
      "metadata": {
        "id": "cXqU28NuBot0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9bc92a-f31e-4c95-862d-e67fe88c7063",
        "id": "FqP29eLRBot0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+---------------------------------------+\n",
            "| THANK YOU FOR USING THE SECRET SHARER |\n",
            "+---------------------------------------+\n",
            "\n",
            " True secrets inserted: 10\n",
            " False secrets inserted: 2\n",
            " Randomness space: 100\n",
            " Training epochs: 7\n",
            " Batch size: 256\n",
            " Secret text: 'my super secret permanent code is 73 04'\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "preparing data...\n"
          ]
        }
      ],
      "source": [
        "# 0. EXPERIMENTAL SETUP ====================================\n",
        "\n",
        "# how many copies of the secret do we insert?\n",
        "numTrueSecrets = 10\n",
        "# how many 'noisy' secrets do we insert?\n",
        "numFalseSecrets = 2\n",
        "# how many ticks are on our lock?\n",
        "numDistinctValues = 100\n",
        "# how long should we train the model?\n",
        "numEpochs = 7\n",
        "batchSize = 256\n",
        "\n",
        "# what form should the secret take?\n",
        "#secretPref = \"my permanent code is \"\n",
        "#secretPref = \"my secret permanent code is \"\n",
        "secretPref = \"my super secret permanent code is \"\n",
        "seqLength = len(secretPref.split())\n",
        "gramSize = seqLength + 1\n",
        "\n",
        "# randomness space\n",
        "secretLength = 2\n",
        "bigR = numDistinctValues ** secretLength\n",
        "\n",
        "# generate a random secret\n",
        "secretText = generateSecret(secretLength, numDistinctValues)\n",
        "insertedSecret = secretPref + secretText\n",
        "\n",
        "print(\"\\n+---------------------------------------+\")\n",
        "print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
        "print(\"+---------------------------------------+\\n\")\n",
        "print(\" True secrets inserted:\", numTrueSecrets)\n",
        "print(\" False secrets inserted:\", numFalseSecrets)\n",
        "print(\" Randomness space:\", numDistinctValues)\n",
        "print(\" Training epochs:\", numEpochs)\n",
        "print(\" Batch size:\", batchSize)\n",
        "print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"\\npreparing data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFnzheIXBot1"
      },
      "outputs": [],
      "source": [
        "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
        "#d here is all possible secrets\n",
        "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
        "# get some noise from these fake secret to add to training\n",
        "\n",
        "if numFalseSecrets > 0:\n",
        "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
        "    noiseDF = pd.DataFrame(noise)\n",
        "\n",
        "testSecret = pd.DataFrame(d);\n",
        "#test data has all possible secrets in it now\n",
        "dataRawT = dataRawT.append(d)\n",
        "#data for dct\n",
        "dataRawdct = dataRaw.append(d)\n",
        "\n",
        "d = []\n",
        "# several in training data\n",
        "for i in range(numTrueSecrets):\n",
        "    d.append({'id' : rootId,\n",
        "              'text' : insertedSecret,\n",
        "              'noPunc' : insertedSecret,\n",
        "              'splchk' : insertedSecret})\n",
        "    rootId += 1\n",
        "#truesecrets add in train data\n",
        "trainSecret = pd.DataFrame(d)\n",
        "dataRawR = dataRawR.append(d)\n",
        "#also the noise is added to train set\n",
        "if numFalseSecrets > 0:\n",
        "    dataRawR = dataRawR.append(noiseDF)\n",
        "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
        "\n",
        "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
        "\n",
        "d = []\n",
        "gid = 0\n",
        "for i in range(len(dataRawR)):\n",
        "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsR = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawV)):\n",
        "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsV = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawT)):\n",
        "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsT = pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zjed27IBot2"
      },
      "outputs": [],
      "source": [
        "# word IDs\n",
        "#dct from dataRaw\n",
        "dct = dict()\n",
        "# word frequencies\n",
        "dctFreq = dict()\n",
        "did = 0\n",
        "for i in range(len(dataRawdct)):\n",
        "    s = dataRawdct.splchk.iloc[i].split()\n",
        "    for w in s:\n",
        "        if w not in dct:\n",
        "            dct[w] = did\n",
        "            did += 1\n",
        "            dctFreq[w] = 1\n",
        "        else:\n",
        "            dctFreq[w] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJPRrGawBot2"
      },
      "outputs": [],
      "source": [
        "dctNoSingle = dict()\n",
        "did = 0\n",
        "for w in list(dct.keys()):\n",
        "    if dctFreq[w] !=1:\n",
        "        dctNoSingle[w] = did\n",
        "        did += 1\n",
        "        \n",
        "dct = dctNoSingle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U01z5OmaBot3"
      },
      "outputs": [],
      "source": [
        "def noSingleUseWords(tup):\n",
        "    for w in tup:\n",
        "        if w not in dct:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "dataGramsR = dataGramsR[dataGramsR['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsT = dataGramsT[dataGramsT['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsV = dataGramsV[dataGramsV['data'].apply(noSingleUseWords) == True]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v2HU5yMBot3"
      },
      "outputs": [],
      "source": [
        "def encodeText(tup):\n",
        "    code = [None] * len(tup)\n",
        "    for i in range(len(tup)):\n",
        "        code[i] = dct[tup[i]]  \n",
        "    return tuple(code)\n",
        "\n",
        "dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n",
        "dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
        "dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nFpG-k-Bot4"
      },
      "outputs": [],
      "source": [
        "dataGramsR['x'] = dataGramsR['codes'].apply(dataSplit)\n",
        "dataGramsR['y'] = dataGramsR['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
        "dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsV['x'] = dataGramsV['codes'].apply(dataSplit)\n",
        "dataGramsV['y'] = dataGramsV['codes'].apply(labelSplit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geFWoJn9Bot4"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "xr = np.zeros((len(dataGramsR), seqLength), dtype = int) \n",
        "yr = np.zeros((len(dataGramsR)), dtype = int)\n",
        "for i in range(len(dataGramsR)):\n",
        "    for j in range(len(dataGramsR.x.iloc[i])):\n",
        "        xr[i][j] = dataGramsR.x.iloc[i][j]\n",
        "    yr[i] = dataGramsR.y.iloc[i]\n",
        "\n",
        "# validation\n",
        "xv = np.zeros((len(dataGramsV), seqLength), dtype = int)\n",
        "yv = np.zeros((len(dataGramsV)), dtype = int)    \n",
        "for i in range(len(dataGramsV)):\n",
        "    for j in range(len(dataGramsV.x.iloc[i])):\n",
        "        xv[i][j] = dataGramsV.x.iloc[i][j]\n",
        "    yv[i] = dataGramsV.y.iloc[i]\n",
        "    \n",
        "# testing\n",
        "xt = np.zeros((len(dataGramsT), seqLength), dtype = int)\n",
        "yt = np.zeros((len(dataGramsT)), dtype = int)\n",
        "for i in range(len(dataGramsT)):\n",
        "    for j in range(len(dataGramsT.x.iloc[i])):\n",
        "        xt[i][j] = dataGramsT.x.iloc[i][j]\n",
        "    yt[i] = dataGramsT.y.iloc[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to add numbers that are not in dictionary to the dictionary\n",
        "counter = len(dct)\n",
        "for i in range(150):\n",
        "  if str(i) not in dct:\n",
        "    counter += 1\n",
        "    dct[str(i)] = counter"
      ],
      "metadata": {
        "id": "PJc-SIAaBot5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(dct)\n",
        "vocabSize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55891284-51d7-4398-91fa-06d774ef722c",
        "id": "cgJnPDgEBot5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9558"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnh5FPJ1Bot6"
      },
      "outputs": [],
      "source": [
        "# 5.1 ONE-HOT ENCODE LABEL DATA ----------------------------\n",
        "# training\n",
        "\n",
        "\n",
        "b = np.zeros((len(yr), vocabSize))\n",
        "b[np.arange(len(yr)), yr] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q8RuuhaBot6"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "\n",
        "\n",
        "bv = np.zeros((len(yv), vocabSize))\n",
        "bv[np.arange(len(yv)), yv] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKwEF9LNBot6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "65a290cc-1302-4150-c907-56c4bcd87c5b",
        "id": "ZANS6Z-LBot7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 276
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vtwT-BuBot7"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmnz2sNgBot7"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQTbJtZNBot7"
      },
      "outputs": [],
      "source": [
        "# 5.2 COMPILE MODEL ----------------------------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabSize, seqLength, input_length = seqLength))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocabSize, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUwqXjF4Bot8"
      },
      "outputs": [],
      "source": [
        "#plot_model(model, to_file='LSTM_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73c4b39-d1f1-47b1-fa50-6672b06a3521",
        "id": "MLT2WQLTBot8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model...\n",
            "Epoch 1/7\n",
            "313/313 [==============================] - 9s 19ms/step - loss: 7.0046 - accuracy: 0.0419 - val_loss: 6.7976 - val_accuracy: 0.0393\n",
            "Epoch 2/7\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 6.6341 - accuracy: 0.0418 - val_loss: 6.7882 - val_accuracy: 0.0393\n",
            "Epoch 3/7\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 6.6060 - accuracy: 0.0423 - val_loss: 6.7936 - val_accuracy: 0.0393\n",
            "Epoch 4/7\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 6.5666 - accuracy: 0.0425 - val_loss: 6.7526 - val_accuracy: 0.0391\n",
            "Epoch 5/7\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 6.4689 - accuracy: 0.0434 - val_loss: 6.6870 - val_accuracy: 0.0393\n",
            "Epoch 6/7\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 6.3336 - accuracy: 0.0473 - val_loss: 6.6002 - val_accuracy: 0.0451\n",
            "Epoch 7/7\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 6.1881 - accuracy: 0.0508 - val_loss: 6.5686 - val_accuracy: 0.0489\n"
          ]
        }
      ],
      "source": [
        "print(\"training model...\")\n",
        "history = model.fit(xr, b, batch_size = batchSize, epochs = numEpochs, verbose = True,\n",
        "                    validation_data = (xv, bv))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xv, bv, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838d2554-dd57-4d5e-8623-346e89886808",
        "id": "WUI1d04XBot8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "624/624 - 3s - loss: 6.5686 - accuracy: 0.0489 - 3s/epoch - 4ms/step\n",
            "Accuracy: 4.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff01a6af-b6a5-48a2-d369-467f36bd0849",
        "id": "OB3HBnAgBot9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RQ6-seclen6-3.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'RQ6-seclen6-3.sav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RQ7**"
      ],
      "metadata": {
        "id": "Zvz1meqApVHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this research question we want to see if the number of epochs change the value for exposure. "
      ],
      "metadata": {
        "id": "Iv3Q8l3mpVHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)"
      ],
      "metadata": {
        "id": "mHYCh8gZpVHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d60be5-6a11-4999-fe34-484388932344",
        "id": "nf-3DDoGpVHF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+---------------------------------------+\n",
            "| THANK YOU FOR USING THE SECRET SHARER |\n",
            "+---------------------------------------+\n",
            "\n",
            " True secrets inserted: 100\n",
            " False secrets inserted: 2\n",
            " Randomness space: 100\n",
            " Training epochs: 7\n",
            " Batch size: 256\n",
            " Secret text: 'my permanent code is 62 35'\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "preparing data...\n"
          ]
        }
      ],
      "source": [
        "# 0. EXPERIMENTAL SETUP ====================================\n",
        "\n",
        "# how many copies of the secret do we insert?\n",
        "numTrueSecrets = 100\n",
        "# how many 'noisy' secrets do we insert?\n",
        "numFalseSecrets = 2\n",
        "# how many ticks are on our lock?\n",
        "numDistinctValues = 100\n",
        "# how long should we train the model?\n",
        "numEpochs = 7\n",
        "batchSize = 256\n",
        "\n",
        "# what form should the secret take?\n",
        "secretPref = \"my permanent code is \"\n",
        "seqLength = len(secretPref.split())\n",
        "gramSize = seqLength + 1\n",
        "\n",
        "# randomness space\n",
        "secretLength = 2\n",
        "bigR = numDistinctValues ** secretLength\n",
        "\n",
        "# generate a random secret\n",
        "secretText = generateSecret(secretLength, numDistinctValues)\n",
        "insertedSecret = secretPref + secretText\n",
        "\n",
        "print(\"\\n+---------------------------------------+\")\n",
        "print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
        "print(\"+---------------------------------------+\\n\")\n",
        "print(\" True secrets inserted:\", numTrueSecrets)\n",
        "print(\" False secrets inserted:\", numFalseSecrets)\n",
        "print(\" Randomness space:\", numDistinctValues)\n",
        "print(\" Training epochs:\", numEpochs)\n",
        "print(\" Batch size:\", batchSize)\n",
        "print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"\\npreparing data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SofYHAE0pVHF"
      },
      "outputs": [],
      "source": [
        "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
        "#d here is all possible secrets\n",
        "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
        "# get some noise from these fake secret to add to training\n",
        "\n",
        "if numFalseSecrets > 0:\n",
        "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
        "    noiseDF = pd.DataFrame(noise)\n",
        "\n",
        "testSecret = pd.DataFrame(d);\n",
        "#test data has all possible secrets in it now\n",
        "dataRawT = dataRawT.append(d)\n",
        "#data for dct\n",
        "dataRawdct = dataRaw.append(d)\n",
        "\n",
        "d = []\n",
        "# several in training data\n",
        "for i in range(numTrueSecrets):\n",
        "    d.append({'id' : rootId,\n",
        "              'text' : insertedSecret,\n",
        "              'noPunc' : insertedSecret,\n",
        "              'splchk' : insertedSecret})\n",
        "    rootId += 1\n",
        "#truesecrets add in train data\n",
        "trainSecret = pd.DataFrame(d)\n",
        "dataRawR = dataRawR.append(d)\n",
        "#also the noise is added to train set\n",
        "if numFalseSecrets > 0:\n",
        "    dataRawR = dataRawR.append(noiseDF)\n",
        "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
        "\n",
        "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
        "\n",
        "d = []\n",
        "gid = 0\n",
        "for i in range(len(dataRawR)):\n",
        "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsR = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawV)):\n",
        "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsV = pd.DataFrame(d)\n",
        "\n",
        "d = []\n",
        "for i in range(len(dataRawT)):\n",
        "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
        "    for g in grams:\n",
        "        d.append({'id' : gid,\n",
        "                  'data' : g})   \n",
        "        gid += 1\n",
        "\n",
        "dataGramsT = pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAW1af88pVHG"
      },
      "outputs": [],
      "source": [
        "# word IDs\n",
        "#dct from dataRaw\n",
        "dct = dict()\n",
        "# word frequencies\n",
        "dctFreq = dict()\n",
        "did = 0\n",
        "for i in range(len(dataRawdct)):\n",
        "    s = dataRawdct.splchk.iloc[i].split()\n",
        "    for w in s:\n",
        "        if w not in dct:\n",
        "            dct[w] = did\n",
        "            did += 1\n",
        "            dctFreq[w] = 1\n",
        "        else:\n",
        "            dctFreq[w] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSjR2Be7pVHG"
      },
      "outputs": [],
      "source": [
        "dctNoSingle = dict()\n",
        "did = 0\n",
        "for w in list(dct.keys()):\n",
        "    if dctFreq[w] !=1:\n",
        "        dctNoSingle[w] = did\n",
        "        did += 1\n",
        "        \n",
        "dct = dctNoSingle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvEWi1yupVHG"
      },
      "outputs": [],
      "source": [
        "def noSingleUseWords(tup):\n",
        "    for w in tup:\n",
        "        if w not in dct:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "dataGramsR = dataGramsR[dataGramsR['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsT = dataGramsT[dataGramsT['data'].apply(noSingleUseWords) == True]\n",
        "dataGramsV = dataGramsV[dataGramsV['data'].apply(noSingleUseWords) == True]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTIC0hU3pVHH"
      },
      "outputs": [],
      "source": [
        "def encodeText(tup):\n",
        "    code = [None] * len(tup)\n",
        "    for i in range(len(tup)):\n",
        "        code[i] = dct[tup[i]]  \n",
        "    return tuple(code)\n",
        "\n",
        "dataGramsR['codes'] = dataGramsR['data'].apply(encodeText)\n",
        "dataGramsT['codes'] = dataGramsT['data'].apply(encodeText)\n",
        "dataGramsV['codes'] = dataGramsV['data'].apply(encodeText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLyS9UpppVHH"
      },
      "outputs": [],
      "source": [
        "dataGramsR['x'] = dataGramsR['codes'].apply(dataSplit)\n",
        "dataGramsR['y'] = dataGramsR['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsT['x'] = dataGramsT['codes'].apply(dataSplit)\n",
        "dataGramsT['y'] = dataGramsT['codes'].apply(labelSplit)\n",
        "\n",
        "dataGramsV['x'] = dataGramsV['codes'].apply(dataSplit)\n",
        "dataGramsV['y'] = dataGramsV['codes'].apply(labelSplit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LqZuVAgpVHH"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "xr = np.zeros((len(dataGramsR), seqLength), dtype = int) \n",
        "yr = np.zeros((len(dataGramsR)), dtype = int)\n",
        "for i in range(len(dataGramsR)):\n",
        "    for j in range(len(dataGramsR.x.iloc[i])):\n",
        "        xr[i][j] = dataGramsR.x.iloc[i][j]\n",
        "    yr[i] = dataGramsR.y.iloc[i]\n",
        "\n",
        "# validation\n",
        "xv = np.zeros((len(dataGramsV), seqLength), dtype = int)\n",
        "yv = np.zeros((len(dataGramsV)), dtype = int)    \n",
        "for i in range(len(dataGramsV)):\n",
        "    for j in range(len(dataGramsV.x.iloc[i])):\n",
        "        xv[i][j] = dataGramsV.x.iloc[i][j]\n",
        "    yv[i] = dataGramsV.y.iloc[i]\n",
        "    \n",
        "# testing\n",
        "xt = np.zeros((len(dataGramsT), seqLength), dtype = int)\n",
        "yt = np.zeros((len(dataGramsT)), dtype = int)\n",
        "for i in range(len(dataGramsT)):\n",
        "    for j in range(len(dataGramsT.x.iloc[i])):\n",
        "        xt[i][j] = dataGramsT.x.iloc[i][j]\n",
        "    yt[i] = dataGramsT.y.iloc[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to add numbers that are not in dictionary to the dictionary\n",
        "counter = len(dct)\n",
        "for i in range(150):\n",
        "  if str(i) not in dct:\n",
        "    counter += 1\n",
        "    dct[str(i)] = counter"
      ],
      "metadata": {
        "id": "3FzUz1ylpVHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabSize = len(dct)\n",
        "vocabSize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d8856a-b925-4134-cb60-eab39b4983c5",
        "id": "xIa240DDpVHH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8597"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pzVE-J2pVHH"
      },
      "outputs": [],
      "source": [
        "# 5.1 ONE-HOT ENCODE LABEL DATA ----------------------------\n",
        "# training\n",
        "\n",
        "\n",
        "b = np.zeros((len(yr), vocabSize))\n",
        "b[np.arange(len(yr)), yr] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3Jsis7dpVHI"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "\n",
        "\n",
        "bv = np.zeros((len(yv), vocabSize))\n",
        "bv[np.arange(len(yv)), yv] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOKBK97UpVHI"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc3806a0-ad15-48cd-9f3e-95fb38e2b1da",
        "id": "cpovlUz7pVHI"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69Sxxr4fpVHI"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLN0ttpppVHI"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxeb4c7upVHI"
      },
      "outputs": [],
      "source": [
        "# 5.2 COMPILE MODEL ----------------------------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabSize, seqLength, input_length = seqLength))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(vocabSize, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBf2jvvhpVHI"
      },
      "outputs": [],
      "source": [
        "#plot_model(model, to_file='LSTM_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87f9d8b-0c6a-4dd7-b7da-5c7e25350604",
        "id": "xcF6BdNRpVHJ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model...\n",
            "Epoch 1/7\n",
            "383/383 [==============================] - 9s 16ms/step - loss: 6.9481 - accuracy: 0.0384 - val_loss: 6.7248 - val_accuracy: 0.0373\n",
            "Epoch 2/7\n",
            "383/383 [==============================] - 5s 12ms/step - loss: 6.5985 - accuracy: 0.0441 - val_loss: 6.6494 - val_accuracy: 0.0478\n",
            "Epoch 3/7\n",
            "383/383 [==============================] - 4s 11ms/step - loss: 6.3786 - accuracy: 0.0566 - val_loss: 6.3160 - val_accuracy: 0.0656\n",
            "Epoch 4/7\n",
            "383/383 [==============================] - 4s 11ms/step - loss: 5.9779 - accuracy: 0.0874 - val_loss: 6.0396 - val_accuracy: 0.0975\n",
            "Epoch 5/7\n",
            "383/383 [==============================] - 4s 11ms/step - loss: 5.6593 - accuracy: 0.1064 - val_loss: 5.8902 - val_accuracy: 0.1108\n",
            "Epoch 6/7\n",
            "383/383 [==============================] - 4s 11ms/step - loss: 5.4373 - accuracy: 0.1214 - val_loss: 5.7754 - val_accuracy: 0.1218\n",
            "Epoch 7/7\n",
            "383/383 [==============================] - 4s 11ms/step - loss: 5.2511 - accuracy: 0.1344 - val_loss: 5.6852 - val_accuracy: 0.1331\n"
          ]
        }
      ],
      "source": [
        "print(\"training model...\")\n",
        "history = model.fit(xr, b, batch_size = batchSize, epochs = numEpochs, verbose = True,\n",
        "                    validation_data = (xv, bv))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xv, bv, verbose=2)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0802750-4ef9-430f-f222-9e48168208ef",
        "id": "GvJQwz6JpVHJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "759/759 - 3s - loss: 5.6852 - accuracy: 0.1331 - 3s/epoch - 4ms/step\n",
            "Accuracy: 13.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exposure**"
      ],
      "metadata": {
        "id": "IjBqONWsNQaj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96QphS2R-IK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819b9f65-cd2f-4d50-e2eb-eca9f7a6a513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating exposure...\n",
            "1/1 [==============================] - 1s 657ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n"
          ]
        }
      ],
      "source": [
        "# 6. CALCULATE EXPOSURE ====================================\n",
        "\n",
        "print(\"calculating exposure...\")\n",
        "\n",
        "# 6.1 ENUMERATE OVER EVERY POSSIBLE SECRET -----------------\n",
        "#why start is this?\n",
        "start = len(xt)-secretLength*(numDistinctValues**secretLength)\n",
        "\n",
        "#here we have 100 vectors of len 100\n",
        "p0 = np.ones((numDistinctValues, numDistinctValues), dtype = float)\n",
        "for i in range(start, len(xt), 2 * numDistinctValues):\n",
        "    #print(i)\n",
        "    #this k creates 0 to 99 index\n",
        "    k = int((i-start) / (2 * numDistinctValues))\n",
        "    #print(k)\n",
        "    #here in this for loop we will fill each of 100 vectors by numeric probs function\n",
        "    #what is the values in numeric probs?\n",
        "    #here in p0 we have 100 probs value for 100 possible numbers (from 0 to 99) that can be the next prediction\n",
        "    p0[k] = numericProbs(xt, numDistinctValues, dct, seqLength, model, i)\n",
        "    # this is the prediction for the next index\n",
        "    # we know that a secret devide into two parts for prediction, once the first numeric value then the second\n",
        "    p1 = numericProbs(xt, numDistinctValues, dct, seqLength, model, i + 1)\n",
        "    # then here we have prob for a combination each time, what is the prob of observing 09 18 for example\n",
        "    #the len would be 10000 since the we set numDistinctValues to 100\n",
        "    # we have prob for each combination here to see after the phrase \"my permanent code is\"\n",
        "    p0[k] = p0[k][k] * p1\n",
        "\n",
        "    #then we sort these \n",
        "scoresRaw = np.argsort(p0, None)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.2 CALCULATE RANKS OF ALL SECRETS -----------------------\n",
        "d = []\n",
        "for i in range(len(scoresRaw)):\n",
        "    d.append({'rank' : i + 1,\n",
        "              'secret1' : int(scoresRaw[i] / numDistinctValues),\n",
        "              'secret2' : scoresRaw[i] % numDistinctValues,\n",
        "              'secretActual1' : int(insertedSecret.split()[-2]),\n",
        "              'secretActual2' : int(insertedSecret.split()[-1])})"
      ],
      "metadata": {
        "id": "onswVihL3v9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.3 CALCULATE EXPOSURE OF INSERTED SECRET ----------------\n",
        "secretRanks = pd.DataFrame(d)\n",
        "secretMatch1 = secretRanks[secretRanks.secret1 == secretRanks.secretActual1]\n",
        "secretMatch2 = int(secretMatch1[secretMatch1.secret2 == secretMatch1.secretActual2]['rank'])\n",
        "\n",
        "exposure = log(bigR, 2) - log(secretMatch2, 2)"
      ],
      "metadata": {
        "id": "CQ5BLw6cV-xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exposure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsuTrO2JUVM3",
        "outputId": "230a4df3-8af2-4e82-85bc-51b4d6773fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.28771237954945"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fno6A0NmaDq9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4df99ae1-4724-4008-84e6-2c9660bff46e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nh = history.history\\nh1 = h[\\'acc\\']\\nh2 = h[\\'val_acc\\']\\nh1df = pd.DataFrame(h1)\\nh2df = pd.DataFrame(h2)\\nh1df.to_csv(\"trainAcc.csv\", sep = \",\", index = False)\\nh2df.to_csv(\"valAcc.csv\", sep = \",\", index = False)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# 6.4 APPEND RESULTS TO DATA SET ---------------------------\n",
        "d = []\n",
        "d.append({'numEpochs' : numEpochs,\n",
        "          'batchSize' : batchSize,\n",
        "          'numTrueSecrets' : numTrueSecrets,\n",
        "          'numFalseSecrets' : numFalseSecrets,\n",
        "          'randomnessSpace' : numDistinctValues,\n",
        "          'secretPrefixLength' : seqLength,\n",
        "          'secretType' : secretPref,\n",
        "          'exposure': exposure})\n",
        "\n",
        "results = pd.DataFrame(d)\n",
        "\n",
        "fileName = \"RQ1-1sec-2.csv\"\n",
        "# if file does not exist write header \n",
        "if not os.path.isfile(fileName):\n",
        "   results.to_csv(fileName, sep = ',', index = False)\n",
        "else: # else it exists so append without writing the header\n",
        "   results.to_csv(fileName, mode = 'a', sep = ',', header = False, index = False)\n",
        "\"\"\"\n",
        "h = history.history\n",
        "h1 = h['acc']\n",
        "h2 = h['val_acc']\n",
        "h1df = pd.DataFrame(h1)\n",
        "h2df = pd.DataFrame(h2)\n",
        "h1df.to_csv(\"trainAcc.csv\", sep = \",\", index = False)\n",
        "h2df.to_csv(\"valAcc.csv\", sep = \",\", index = False)\n",
        "\"\"\""
      ]
    }
  ]
}