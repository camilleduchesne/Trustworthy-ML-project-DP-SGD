{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4beb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107530af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleduchesne/miniforge3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import ngrams \n",
    "# Check for TensorFlow GPU access\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# See TensorFlow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb3e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.normalizers import Sequence, Lowercase\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from transformers import GPT2TokenizerFast, GPT2Config,TFGPT2LMHeadModel\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cb9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit(tup):\n",
    "    n = len(tup)\n",
    "    return tup[0 : (n - 1)]\n",
    "\n",
    "def labelSplit(tup):\n",
    "    n = len(tup)\n",
    "    return tup[n - 1]\n",
    "\n",
    "# get word from dictionary ID\n",
    "def getWord(d, i):\n",
    "    return list(d.keys())[list(d.values()).index(i)]\n",
    "\n",
    "#this function generates random numbers for the secret\n",
    "def generateSecret(length, size):\n",
    "    secret = \"\"\n",
    "    for i in range(length):\n",
    "        a = randint(0, size)\n",
    "        if a < 10:\n",
    "            a = \"0\" + str(a)\n",
    "        a = str(a)\n",
    "        secret = secret + a + \" \"\n",
    "    \n",
    "    return secret[:-1]\n",
    "\n",
    "#allows us to add every secret permutation to the \"test\" data set, allowing us to see what probability the model assigns to every value of r\n",
    "def enumerateSecrets(length, size, rid, pref):\n",
    "    d = []\n",
    "    \n",
    "    if length == 1:\n",
    "        for i in range(size):\n",
    "            a = pref + str(i)\n",
    "            d.append({'id' : rid,\n",
    "                      'text' : a,\n",
    "                      'noPunc' : a,\n",
    "                      'splchk' : a})\n",
    "            rid += 1\n",
    "    \n",
    "    if length == 2:\n",
    "        for i in range(size):\n",
    "            a = pref + str(i)\n",
    "            for j in range(size):\n",
    "                b = a + \" \" + str(j)\n",
    "                d.append({'id' : rid,\n",
    "                          'text' : b,\n",
    "                          'noPunc' : b,\n",
    "                          'splchk' : b})\n",
    "                rid += 1\n",
    "                \n",
    "    return d, rid\n",
    "\n",
    "def numericProbs_gpt(x, size, dictionary, gramSize, model, index): \n",
    "    xn = np.zeros((1, gramSize), dtype = float)\n",
    "    for k in range(gramSize):\n",
    "        xn[0][k] = x[index][k]\n",
    "\n",
    "    p0 = model.predict(xn)[0]\n",
    "    \n",
    "    numericProbs_gpt = np.zeros((size), dtype = float)\n",
    "    \n",
    "    for j in range(size):\n",
    "        a = str(j)\n",
    "        numericProbs_gpt[j] = p0[dictionary[a]]\n",
    "        \n",
    "    return numericProbs_gpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5a0c1",
   "metadata": {},
   "source": [
    "## Data Cleaning & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720f7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('smsCorpus_en_2015.03.09_all.json')\n",
    "data = json.load(f)\n",
    "with open(\"smsCorpus_en_2015.03.09_all.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62e0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55835\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10120</td>\n",
       "      <td>Bugis oso near wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10121</td>\n",
       "      <td>Go until jurong point, crazy.. Available only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10122</td>\n",
       "      <td>I dunno until when... Lets go learn pilates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10123</td>\n",
       "      <td>Den only weekdays got special price... Haiz.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10124</td>\n",
       "      <td>Meet after lunch la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     @id                                               text\n",
       "0  10120                              Bugis oso near wat...\n",
       "1  10121   Go until jurong point, crazy.. Available only...\n",
       "2  10122     I dunno until when... Lets go learn pilates...\n",
       "3  10123   Den only weekdays got special price... Haiz.....\n",
       "4  10124                             Meet after lunch la..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listofDict = data['smsCorpus']['message']\n",
    "print(len(listofDict))\n",
    "fullData = pd.DataFrame(listofDict)\n",
    "dataRaw = fullData[['@id','text']]\n",
    "dataRaw = pd.DataFrame(dataRaw)\n",
    "dataRaw['text'] = dataRaw['text'].astype(\"str\")\n",
    "dataRaw['text'] = dataRaw['text'].map(lambda x: x.lstrip(\"{'$':-\").rstrip(\"-'}\"))\n",
    "dataRaw['text'] = dataRaw['text'].str.replace(r\"'\", \"\")\n",
    "dataRaw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5009b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "def cleanSMS(sms):\n",
    "    \n",
    "    # leetspeak\n",
    "    sms = re.sub(\"[\\.,]\", \" \", sms)\n",
    "    sms = re.sub(\" {2,}\", \" \", sms)\n",
    "    sms = re.sub(\" 2 \", \" to \", sms)\n",
    "    sms = re.sub(\" 4 | fr \", \" for \", sms)\n",
    "    \n",
    "    sms = re.sub(\" abt \", \" about \", sms)\n",
    "    sms = re.sub(\" aft \", \" after \", sms)\n",
    "    sms = re.sub(\" ard \", \" around \", sms)\n",
    "    \n",
    "    sms = re.sub(\" ar \", \" all right \", sms)\n",
    "    sms = re.sub(\" ar$\", \" all right\", sms)\n",
    "    \n",
    "    sms = re.sub(\" b \", \" be \", sms)\n",
    "    sms = re.sub(\" bcz \", \" because \", sms)\n",
    "    sms = re.sub(\" bday \", \" birthday\", sms)\n",
    "    sms = re.sub(\" brin \", \" bring \", sms)\n",
    "    \n",
    "    sms = re.sub(\" btw \", \" by the way \", sms)\n",
    "    sms = re.sub(\" btw$\", \" by the way\", sms)\n",
    "    \n",
    "    sms = re.sub(\" buk \", \" book \", sms)\n",
    "    \n",
    "    sms = re.sub(\" c \", \" see \", sms)\n",
    "    sms = re.sub(\"^c \", \"see \", sms)\n",
    "    \n",
    "    sms = re.sub(\" coz | cuz | cos \", \" cause \", sms)\n",
    "    sms = re.sub(\"^coz |^cuz |^cos \", \"cause \", sms)\n",
    "    \n",
    "    sms = re.sub(\" da \", \" the \", sms)\n",
    "    sms = re.sub(\" dat \", \" that \", sms)\n",
    "    \n",
    "    sms = re.sub(\" den \", \" then \", sms)\n",
    "    sms = re.sub(\"^den \", \"then \", sms)\n",
    "    sms = re.sub(\" den$\", \" then\", sms)\n",
    "    \n",
    "    sms = re.sub(\" dint? \", \" did not \", sms)\n",
    "    \n",
    "    sms = re.sub(\" dis \", \" this \", sms)\n",
    "    sms = re.sub(\" dis$\", \" this\", sms)\n",
    "    \n",
    "    sms = re.sub(\" dem | dm \", \" them \", sms)\n",
    "    sms = re.sub(\" dey \", \" they \", sms)\n",
    "    sms = re.sub(\"^dey \", \"they \", sms)\n",
    "    sms = re.sub(\" dnt \", \" do not \", sms)\n",
    "    \n",
    "    sms = re.sub(\" dun | don \", \" do not \", sms)\n",
    "    sms = re.sub(\"^dun |^don \", \"do not \", sms)\n",
    "    sms = re.sub(\" dun$| don$\", \" do not\", sms)\n",
    "    \n",
    "    sms = re.sub(\" e \", \" the \", sms)\n",
    "    sms = re.sub(\" esp \" , \" especially \", sms)\n",
    "    sms = re.sub(\" enuff \", \" enough \", sms)\n",
    "    sms = re.sub(\" frens \", \" friends \", sms)\n",
    "    \n",
    "    sms = re.sub(\" fren \" , \" friend \", sms)\n",
    "    sms = re.sub(\" fren$\", \" fren\", sms)\n",
    "    \n",
    "    sms = re.sub(\" frm \", \" from \", sms)\n",
    "    \n",
    "    sms = re.sub(\" gd \", \" good \", sms)\n",
    "    sms = re.sub(\"^gd \", \"good \", sms)\n",
    "    sms = re.sub(\" gd$\", \" good\", sms)\n",
    "    \n",
    "    sms = re.sub(\" gn \", \" good night \", sms)\n",
    "    sms = re.sub(\"^gn \", \"good night \", sms)\n",
    "    sms = re.sub(\" gn$\", \" good night\", sms)\n",
    "    \n",
    "    sms = re.sub(\"^hai \", \"hey \", sms)\n",
    "    \n",
    "    sms = re.sub(\" haf | hv | hav \", \" have \", sms)\n",
    "    sms = re.sub(\" haf$| hv$| hav$\", \" have\", sms)\n",
    "    \n",
    "    sms = re.sub(\" haven \", \" have not \", sms)\n",
    "    \n",
    "    sms = re.sub(\" hse \", \" house \", sms)\n",
    "    sms = re.sub(\" hse$\", \" house\", sms)\n",
    "    sms = re.sub(\" hw \", \" homework \", sms)\n",
    "    sms = re.sub(\"^hw \", \"how \", sms)\n",
    "    \n",
    "    sms = re.sub(\" i ll \", \" i will \", sms)\n",
    "    sms = re.sub(\"^i ll \", \"i will \", sms)\n",
    "    sms = re.sub(\" i ve \", \" i have \", sms)\n",
    "    sms = re.sub(\"^i ve \", \"i have \", sms)\n",
    "    \n",
    "    sms = re.sub(\" juz | jus | jos \", \" just \", sms)\n",
    "    sms = re.sub(\"^juz |^jus |^jos \", \"just \", sms)\n",
    "    \n",
    "    sms = re.sub(\"kd \", \"ked \", sms)\n",
    "    sms = re.sub(\" knw \", \" know \", sms)\n",
    "    \n",
    "    sms = re.sub(\" lar | lter \", \" later \", sms)\n",
    "    sms = re.sub(\" lar$| lter$\", \" later\", sms)\n",
    "    sms = re.sub(\"^lar |^lter \", \"later \", sms)\n",
    "    \n",
    "    sms = re.sub(\" lib \", \" library \", sms)\n",
    "    sms = re.sub(\" lib$\", \" library\", sms)\n",
    "    \n",
    "    sms = re.sub(\" lect \", \" lecture \", sms)\n",
    "    sms = re.sub(\"^ll \", \"i will \", sms)\n",
    "    sms = re.sub(\" lyk \", \" like \", sms)\n",
    "    sms = re.sub(\" m \", \" am \", sms)\n",
    "    sms = re.sub(\"^m \", \"i am \", sms)\n",
    "    sms = re.sub(\" mayb \", \" maybe \", sms)\n",
    "    sms = re.sub(\" meh \", \" me \", sms)\n",
    "    sms = re.sub(\" msg \", \" message \", sms)\n",
    "    sms = re.sub(\" neva \", \" never \", sms)\n",
    "    sms = re.sub(\" mum \", \" mom \", sms)\n",
    "    sms = re.sub(\" muz \", \" must \", sms)\n",
    "    sms = re.sub(\" n \", \" and \", sms)\n",
    "    sms = re.sub(\"nd \", \"ned \", sms)\n",
    "    sms = re.sub(\" nite \", \" night \", sms)\n",
    "    sms = re.sub(\" noe \", \" know \", sms)\n",
    "    \n",
    "    sms = re.sub(\" nt \", \" not \", sms)\n",
    "    sms = re.sub(\"^nt \", \"not \", sms)\n",
    "    \n",
    "    sms = re.sub(\" nvm \", \" never mind \", sms)\n",
    "    sms = re.sub(\" nvr \", \" never \", sms)\n",
    "    sms = re.sub(\" nw \", \" now \", sms)\n",
    "    \n",
    "    sms = re.sub(\" nxt \", \" next \", sms)\n",
    "    sms = re.sub(\"^nxt \", \"next \", sms)\n",
    "    \n",
    "    sms = re.sub(\" okie | ok | k \", \" okay \", sms)\n",
    "    sms = re.sub(\"^okie |^ok |^k \", \"okay \", sms)\n",
    "    sms = re.sub(\" okie$| ok$| k$\", \" okay\", sms)\n",
    "    \n",
    "    sms = re.sub(\" oredi | alr \", \" already \", sms)\n",
    "    sms = re.sub(\" oredi$| alr$\", \" already\", sms)\n",
    "    \n",
    "    sms = re.sub(\" oso \", \" also \", sms)\n",
    "    \n",
    "    sms = re.sub(\" plz \", \" please \", sms)\n",
    "    sms = re.sub(\"^plz \", \"please \", sms)\n",
    "    sms = re.sub(\" plz$\", \" please\", sms)\n",
    "    \n",
    "    sms = re.sub(\" pple? \", \" people \", sms)\n",
    "    \n",
    "    sms = re.sub(\" pg \", \" page \", sms)\n",
    "    sms = re.sub(\" pg$\", \" page\", sms)\n",
    "    \n",
    "    sms = re.sub(\" r \", \" are \", sms)\n",
    "    sms = re.sub(\"^r \", \"are \", sms)\n",
    "    sms = re.sub(\" r$\", \" are\", sms)\n",
    "    \n",
    "    sms = re.sub(\" rem \", \" remember \", sms)\n",
    "    sms = re.sub(\" rite \", \" right \", sms)\n",
    "    \n",
    "    sms = re.sub(\" rly \", \" really \", sms)\n",
    "    sms = re.sub(\"^rly \", \"really \", sms)\n",
    "    sms = re.sub(\" rly$\", \" really\", sms)\n",
    "    \n",
    "    sms = re.sub(\" ru \", \" are you \", sms)\n",
    "    sms = re.sub(\" s \", \" is \", sms)\n",
    "    sms = re.sub(\"^s \", \"its \", sms)\n",
    "    \n",
    "    sms = re.sub(\" sch \", \" school \", sms)\n",
    "    sms = re.sub(\" sch$\", \" school\", sms)\n",
    "    \n",
    "    sms = re.sub(\" shd | shld \", \" should \", sms)\n",
    "    sms = re.sub(\" slp \", \" sleep \", sms)\n",
    "    \n",
    "    sms = re.sub(\" sme\", \" some\", sms)\n",
    "    sms = re.sub(\"^sme\", \"some\", sms)\n",
    "    \n",
    "    sms = re.sub(\" smth \", \" something \", sms)\n",
    "    \n",
    "    sms = re.sub(\" tat \", \" that \", sms)\n",
    "    sms = re.sub(\"^tat \", \"that \", sms)\n",
    "    sms = re.sub(\" tat$\", \" that\", sms)\n",
    "    \n",
    "    sms = re.sub(\" tmr | tml \", \" tomorrow \", sms)\n",
    "    sms = re.sub(\"^tmr |^tml \", \"tomorrow \", sms)\n",
    "    sms = re.sub(\" tmr$| tml$\", \" tomorrow\", sms)\n",
    "    \n",
    "    sms = re.sub(\" thanx \", \" thanks \", sms)\n",
    "    sms = re.sub(\" thanx$\", \" thanks\", sms)\n",
    "    sms = re.sub(\"^thanx \", \"thanks \", sms)\n",
    "    \n",
    "    sms = re.sub(\" thgt \", \" thought \", sms)\n",
    "    sms = re.sub(\" thk | thnk \", \" think \", sms)\n",
    "    \n",
    "    sms = re.sub(\" tis \", \" this \", sms)\n",
    "    sms = re.sub(\" tot \" , \" thought \", sms)\n",
    "    sms = re.sub(\" ttyl$\", \" talk to you later\", sms)\n",
    "    \n",
    "    sms = re.sub(\" tym \", \" time \", sms)\n",
    "    sms = re.sub(\" tym\", \" time\", sms)\n",
    "    \n",
    "    sms = re.sub(\" [uüü] \", \" you \", sms)\n",
    "    sms = re.sub(\"^[uüü] \", \"you \", sms)\n",
    "    sms = re.sub(\" [uüü]$\", \" you\", sms)\n",
    "    \n",
    "    sms = re.sub(\" ur \", \" your \", sms)\n",
    "    sms = re.sub(\" v \", \" very \", sms)\n",
    "    sms = re.sub(\" vil \", \" will \", sms)\n",
    "    sms = re.sub(\"^ve \", \"i have \", sms)\n",
    "    sms = re.sub(\" wan \", \" want \", sms)\n",
    "    sms = re.sub(\" w \", \" with \", sms)\n",
    "    \n",
    "    sms = re.sub(\" wana \", \" wanna \", sms)\n",
    "    sms = re.sub(\"^wana \", \"wanna \", sms)\n",
    "    \n",
    "    sms = re.sub(\" wat \", \" what \", sms)\n",
    "    sms = re.sub(\"^wat \", \"what \", sms)\n",
    "    sms = re.sub(\" wat$\", \" what\", sms)\n",
    "    \n",
    "    sms = re.sub(\" wen \", \" when \", sms)\n",
    "    sms = re.sub(\"^wen \", \"when \", sms)\n",
    "    \n",
    "    sms = re.sub(\" wif | wid | wth \", \" with \", sms)\n",
    "    sms = re.sub(\"^wif |^wid |^wth \", \"with \", sms)\n",
    "    sms = re.sub(\" wif$| wid$| wth$\", \" with\", sms)\n",
    "    \n",
    "    sms = re.sub(\" wk \", \" week \", sms)\n",
    "\n",
    "    sms = re.sub(\" wun \", \" wont \", sms)\n",
    "    \n",
    "    sms = re.sub(\" y \", \" why \", sms)\n",
    "    sms = re.sub(\"^y \", \"why \", sms)\n",
    "    sms = re.sub(\" y$\", \" why\", sms)\n",
    "    \n",
    "    sms = re.sub(\"yup\", \"yep\", sms)\n",
    "\n",
    "    # remove laughter and smiles\n",
    "    sms = re.sub(\" d \", \" \", sms)\n",
    "    sms = re.sub(\" d$\", \"\", sms)\n",
    "    sms = re.sub(\"^d \", \"\", sms)\n",
    "    sms = re.sub(\" ha \", \" \", sms)\n",
    "    sms = re.sub(\"^ha \", \"\", sms)\n",
    "    sms = re.sub(\" ha$, \", \"\", sms)\n",
    "    sms = re.sub(\" lor \", \" \", sms)\n",
    "    sms = re.sub(\" lor$\", \"\", sms)\n",
    "    sms = re.sub(\" lols? \", \" \", sms)\n",
    "    sms = re.sub(\"^lols? \", \"\", sms)\n",
    "    sms = re.sub(\" lols?$\", \"\", sms)\n",
    "    sms = re.sub(\"a*(ha){2,}h*\", \"\", sms)\n",
    "    sms = re.sub(\" hee \", \" \", sms)\n",
    "    sms = re.sub(\"^hee \", \"\", sms)\n",
    "    sms = re.sub(\" hee$\", \"\", sms)\n",
    "    \n",
    "    # remove words I don't understand\n",
    "    sms = re.sub(\" lei \", \" \", sms)\n",
    "    sms = re.sub(\"^lei \", \" \", sms)\n",
    "    sms = re.sub(\" lei$\", \" \", sms)\n",
    "    \n",
    "    # standardize most '-ing' to '-in'\n",
    "    sms = re.sub(\"(?<=[bdfghklmnoprstvwy])ing(?= )\", \"in\", sms)\n",
    "    sms = re.sub(\"(?<=[bdfghklmnoprstvwy])ing$\", \"in\", sms)\n",
    "    \n",
    "    # force spaces between comma- or period-separated words\n",
    "    sms = re.sub(\"(?<=[^ ])[\\.,](?=[^ ])\", \" \", sms)\n",
    "    \n",
    "    return sms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9dccd",
   "metadata": {},
   "source": [
    "#Why do we run dataRaw['splchk'] = dataRaw['noPunc'].apply(cleanSMS) twice more??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9acb4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = dataRaw[:30000]\n",
    "rootId = len(dataRaw)\n",
    "#cleaning\n",
    "myPunc = '!\"#$%&\\()*+-/:;<=>?@[\\\\]^_`{|}~\\''\n",
    "dataRaw['noPunc'] = dataRaw['text'].apply(lambda s: s.translate(str.maketrans('','', myPunc)).lower())\n",
    "dataRaw['splchk'] = dataRaw['noPunc'].apply(cleanSMS)\n",
    "#cleaning\n",
    "dataRaw['splchk'] = dataRaw['noPunc'].apply(cleanSMS)\n",
    "dataRaw['splchk'] = dataRaw['splchk'].apply(cleanSMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe5c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "#we have 20% of the whole data known as dataRaw for test and it is knwon as dataRawT\n",
    "#then the othe 80% is known as dataRawR will soon split to valid and train\n",
    "mskTrain = np.random.rand(len(dataRaw)) < 0.8\n",
    "dataRawR = dataRaw[mskTrain]\n",
    "dataRawT = dataRaw[~mskTrain]\n",
    "\n",
    "# train-validation split\n",
    "mskVal = np.random.rand(len(dataRawR)) < 0.8\n",
    "#Here from the left 80% of the data in dataRawR we have 80% for training known as dataRawR and 20% for validation known as dataRawV\n",
    "dataRawV = dataRawR[~mskVal]\n",
    "dataRawR = dataRawR[mskVal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2333e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---------------------------------------+\n",
      "| THANK YOU FOR USING THE SECRET SHARER |\n",
      "+---------------------------------------+\n",
      "\n",
      " True secrets inserted: 200\n",
      " False secrets inserted: 2\n",
      " Randomness space: 100\n",
      " Training epochs: 5\n",
      " Batch size: 256\n",
      " Secret text: 'my permanent code is 73 04'\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "preparing data...\n"
     ]
    }
   ],
   "source": [
    "# 0. EXPERIMENTAL SETUP ====================================\n",
    "\n",
    "# how many copies of the secret do we insert?\n",
    "numTrueSecrets = 200\n",
    "# how many 'noisy' secrets do we insert?\n",
    "numFalseSecrets = 2\n",
    "# how many ticks are on our lock?\n",
    "numDistinctValues = 100\n",
    "# how long should we train the model?\n",
    "numEpochs = 5\n",
    "batchSize = 256\n",
    "\n",
    "# what form should the secret take?\n",
    "secretPref = \"my permanent code is \"\n",
    "seqLength = len(secretPref.split())\n",
    "gramSize = seqLength + 1\n",
    "\n",
    "# randomness space\n",
    "secretLength = 2\n",
    "bigR = numDistinctValues ** secretLength\n",
    "\n",
    "# generate a random secret\n",
    "secretText = generateSecret(secretLength, numDistinctValues)\n",
    "insertedSecret = secretPref + secretText\n",
    "\n",
    "print(\"\\n+---------------------------------------+\")\n",
    "print(\"| THANK YOU FOR USING THE SECRET SHARER |\")\n",
    "print(\"+---------------------------------------+\\n\")\n",
    "print(\" True secrets inserted:\", numTrueSecrets)\n",
    "print(\" False secrets inserted:\", numFalseSecrets)\n",
    "print(\" Randomness space:\", numDistinctValues)\n",
    "print(\" Training epochs:\", numEpochs)\n",
    "print(\" Batch size:\", batchSize)\n",
    "print(\" Secret text: '\", insertedSecret, \"'\\n\", sep = '')\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"\\npreparing data...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6659746",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, rootId  = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72acc555",
   "metadata": {},
   "outputs": [],
   "source": [
    "if numFalseSecrets > 0:\n",
    "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
    "    noiseDF = pd.DataFrame(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ac34c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/q809tzz55jq3vvvgwlrjq6kr0000gn/T/ipykernel_18303/3714986275.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataRawT = dataRawT.append(d)\n",
      "/var/folders/3x/q809tzz55jq3vvvgwlrjq6kr0000gn/T/ipykernel_18303/3714986275.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataRawdct = dataRaw.append(d)\n",
      "/var/folders/3x/q809tzz55jq3vvvgwlrjq6kr0000gn/T/ipykernel_18303/3714986275.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataRawR = dataRawR.append(d)\n",
      "/var/folders/3x/q809tzz55jq3vvvgwlrjq6kr0000gn/T/ipykernel_18303/3714986275.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataRawR = dataRawR.append(noiseDF)\n"
     ]
    }
   ],
   "source": [
    "d, rootId = enumerateSecrets(secretLength, numDistinctValues, rootId, secretPref)\n",
    "#d here is all possible secrets\n",
    "#for the number of false secrets that we ordered it sample from d and make a data fram with name noise out of that \n",
    "# get some noise from these fake secret to add to training\n",
    "\n",
    "if numFalseSecrets > 0:\n",
    "    noise = [d[i] for i in sorted(random.sample(range(len(d)), numFalseSecrets))]\n",
    "    noiseDF = pd.DataFrame(noise)\n",
    "\n",
    "testSecret = pd.DataFrame(d);\n",
    "#test data has all possible secrets in it now\n",
    "dataRawT = dataRawT.append(d)\n",
    "#data for dct\n",
    "dataRawdct = dataRaw.append(d)\n",
    "\n",
    "d = []\n",
    "# several in training data\n",
    "for i in range(numTrueSecrets):\n",
    "    d.append({'id' : rootId,\n",
    "              'text' : insertedSecret,\n",
    "              'noPunc' : insertedSecret,\n",
    "              'splchk' : insertedSecret})\n",
    "    rootId += 1\n",
    "#truesecrets add in train data\n",
    "trainSecret = pd.DataFrame(d)\n",
    "dataRawR = dataRawR.append(d)\n",
    "#also the noise is added to train set\n",
    "if numFalseSecrets > 0:\n",
    "    dataRawR = dataRawR.append(noiseDF)\n",
    "#the train set have true sectrets and false secrets while test set has all possible secrets\n",
    "\n",
    "# 2.4 SPLIT INTO OVERLAPPING SETS OF WORDS -----------000000\n",
    "\n",
    "d = []\n",
    "gid = 0\n",
    "for i in range(len(dataRawR)):\n",
    "    grams = ngrams(dataRawR.splchk.iloc[i].split(), gramSize)\n",
    "    for g in grams:\n",
    "        d.append({'id' : gid,\n",
    "                  'data' : g})   \n",
    "        gid += 1\n",
    "\n",
    "dataGramsR = pd.DataFrame(d)\n",
    "\n",
    "d = []\n",
    "for i in range(len(dataRawV)):\n",
    "    grams = ngrams(dataRawV.splchk.iloc[i].split(), gramSize)\n",
    "    for g in grams:\n",
    "        d.append({'id' : gid,\n",
    "                  'data' : g})   \n",
    "        gid += 1\n",
    "\n",
    "dataGramsV = pd.DataFrame(d)\n",
    "\n",
    "d = []\n",
    "for i in range(len(dataRawT)):\n",
    "    grams = ngrams(dataRawT.splchk.iloc[i].split(), gramSize)\n",
    "    for g in grams:\n",
    "        d.append({'id' : gid,\n",
    "                  'data' : g})   \n",
    "        gid += 1\n",
    "\n",
    "dataGramsT = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7844be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create functionc to turn Golshid's df to the right format for my tokenizer\n",
    "\n",
    "def prep_token(df):\n",
    "    df['data'] = df['data'].astype(str)\n",
    "    df['data']=df['data'].str.replace(\"(\",\"\") \n",
    "    df['data']=df['data'].str.replace(\")\",\"\")\n",
    "    df['data']=df['data'].str.replace(\",\",\" \")\n",
    "    df['data']=df['data'].str.replace(\"'\",\"\")\n",
    "    return df\n",
    "\n",
    "# merge all the words together as string to find in my next function\n",
    "#new_Df_test = dataGramsT\n",
    "#new_Df_test = dataGramsR.apply(lambda x: x.str.replace(',', ''))\n",
    "#new_Df_test\n",
    "#new_Df_test['data'].str.replace(\" ()\",\"\") \n",
    "#new_Df_test\n",
    "#new_Df_test['data'] = new_Df_test['data'].astype(str)\n",
    "#result = new_Df_test.dtypes\n",
    "#new_Df_test['data']=new_Df_test['data'].str.replace(\"(\",\"\") \n",
    "#new_Df_test['data']=new_Df_test['data'].str.replace(\")\",\"\")\n",
    "#new_Df_test['data']=new_Df_test['data'].str.replace(\",\",\" \")\n",
    "#new_Df_test['data']=new_Df_test['data'].str.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dcb89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/q809tzz55jq3vvvgwlrjq6kr0000gn/T/ipykernel_18303/1269492110.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['data']=df['data'].str.replace(\"(\",\"\")\n",
      "/var/folders/3x/q809tzz55jq3vvvgwlrjq6kr0000gn/T/ipykernel_18303/1269492110.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['data']=df['data'].str.replace(\")\",\"\")\n"
     ]
    }
   ],
   "source": [
    "prep_train=prep_token(dataGramsR)\n",
    "prep_test=prep_token(dataGramsT)\n",
    "prep_val=prep_token(dataGramsV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ef92510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up, change the column name to fit the rest of the code, and drop id\n",
    "prep_train=prep_train.drop(['id'],axis=1)\n",
    "prep_train.columns = ['text']\n",
    "\n",
    "prep_test=prep_test.drop(['id'],axis=1)\n",
    "prep_test.columns = ['text']\n",
    "\n",
    "prep_val=prep_val.drop(['id'],axis=1)\n",
    "prep_test.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f137f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>then  only  weekdays  got  special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>only  weekdays  got  special  price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weekdays  got  special  price  haiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>got  special  price  haiz  cant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>special  price  haiz  cant  eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59815</th>\n",
       "      <td>permanent  code  is  99  97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59816</th>\n",
       "      <td>my  permanent  code  is  99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59817</th>\n",
       "      <td>permanent  code  is  99  98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59818</th>\n",
       "      <td>my  permanent  code  is  99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59819</th>\n",
       "      <td>permanent  code  is  99  99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59820 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text\n",
       "0       then  only  weekdays  got  special\n",
       "1      only  weekdays  got  special  price\n",
       "2      weekdays  got  special  price  haiz\n",
       "3          got  special  price  haiz  cant\n",
       "4          special  price  haiz  cant  eat\n",
       "...                                    ...\n",
       "59815          permanent  code  is  99  97\n",
       "59816          my  permanent  code  is  99\n",
       "59817          permanent  code  is  99  98\n",
       "59818          my  permanent  code  is  99\n",
       "59819          permanent  code  is  99  99\n",
       "\n",
       "[59820 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check, works like a charm!\n",
    "#prep_train\n",
    "prep_test\n",
    "#prep_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909b299",
   "metadata": {},
   "source": [
    "not sure this one is usefull anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f2bb190",
   "metadata": {},
   "outputs": [],
   "source": [
    " #TRAINING SET\n",
    "#dataRawR.head() #Corresponds to the training data\n",
    "#dataRawR.tail() # validate that the training set has the right amount of true tokens and the false tokens\n",
    "\n",
    "#TEST SET\n",
    "#dataRawT.head()\n",
    "#dataRawT.tail()\n",
    "\n",
    "#VALIDATION SET\n",
    "#dataRawV.head()\n",
    "#dataRawV.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9087edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    " #pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96cc5505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "4.17.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import random\n",
    "import datasets\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, TFGPT2LMHeadModel\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "pd.options.display.max_colwidth = 6000\n",
    "pd.options.display.max_rows = 400\n",
    "np.set_printoptions(suppress=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Log Level and suppress extensive tf warnings\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"info\"\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "print(tf.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "859bc805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "import tensorflow_hub as hub\n",
    "#import tensorflow_text as text\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f96f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is based on the post-cleaned test set, for calculating the exposure metric, we need only the 4 first tokens\n",
    "#The function from above was thus updated\n",
    "#xt_inprocess = modif_test.values.tolist()\n",
    "xt_inprocess=prep_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70108b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xt(lst):\n",
    "    res=[]\n",
    "    first_1=[]\n",
    "    final_first_1=[]\n",
    "    list_3 = []\n",
    "    text_file=[]\n",
    "    for i in range(0,len(lst)):\n",
    "        text_file=lst[i]\n",
    "        \n",
    "        for j in range(0,len(text_file)):\n",
    "            first_1=re.split(\" \", text_file[j])\n",
    "            final_first_1 = first_1[0:4]\n",
    "            joint_toget = [\" \".join([str(item) for item in final_first_1])]\n",
    "            res.append(joint_toget)\n",
    "    \n",
    "    #new_list = [lst[j:j+1] for j in range(len(lst)-stopping,len(lst))] \n",
    "    #list_3.extend(res + new_list)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7911578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_CD=create_xt(xt_inprocess)\n",
    "#print(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b0ea622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go  until  jurong  point  crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>until  jurong  point  crazy  available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jurong  point  crazy  available  only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>point  crazy  available  only  in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crazy  available  only  in  bugis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130590</th>\n",
       "      <td>permanent  code  is  73  04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130591</th>\n",
       "      <td>my  permanent  code  is  2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130592</th>\n",
       "      <td>permanent  code  is  2  43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130593</th>\n",
       "      <td>my  permanent  code  is  94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130594</th>\n",
       "      <td>permanent  code  is  94  71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130595 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text\n",
       "0              go  until  jurong  point  crazy\n",
       "1       until  jurong  point  crazy  available\n",
       "2        jurong  point  crazy  available  only\n",
       "3            point  crazy  available  only  in\n",
       "4            crazy  available  only  in  bugis\n",
       "...                                        ...\n",
       "130590             permanent  code  is  73  04\n",
       "130591              my  permanent  code  is  2\n",
       "130592              permanent  code  is  2  43\n",
       "130593             my  permanent  code  is  94\n",
       "130594             permanent  code  is  94  71\n",
       "\n",
       "[130595 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternative Golshid, having split each sentence into blocks of length 4, so there is more data in this one\n",
    "#the names of the sets are :  (train, test, val)\n",
    "\n",
    "prep_test\n",
    "prep_val\n",
    "prep_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cab422",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3555b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset, load_dataset\n",
    "stunt_double_train=prep_train.iloc[:200] ##(i made it mini for the time being)\n",
    "data=Dataset.from_pandas(prep_train)\n",
    "\n",
    "#test set\n",
    "test_set =prep_test.iloc[:200]\n",
    "test_set=Dataset.from_pandas(prep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f4edb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tokenizer and logger\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "MAX_TOKENS = 10\n",
    "POS_TOKEN = \"<|review_pos|>\"\n",
    "NEG_TOKEN = \"<|review_neg|>\"\n",
    "BOS_TOKENS = [NEG_TOKEN, POS_TOKEN]\n",
    "EOS_TOKEN = \"<|endoftext|>\"\n",
    "PAD_TOKEN = \"<|pad|>\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-large',eos_token=EOS_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    max_length=MAX_TOKENS,\n",
    "    is_split_into_words=True)\n",
    "tokenizer.add_tokens(BOS_TOKENS, special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7913fb8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 59820\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8892d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2900a9414522409485ca0890f51e786b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 130595\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "output = {}\n",
    "# texts to numeric vectors of MAX_TOKENS\n",
    "def tokenize_function(examples, tokenizer=tokenizer):\n",
    "    # Add start and end token to each comment\n",
    "    examples = [ex + EOS_TOKEN for ex in examples[\"text\"]]\n",
    "    # tokenizer created input_ids and attention_mask as output\n",
    "    output = tokenizer(\n",
    "        examples,\n",
    "        add_special_tokens=True,  # Only adds pad not eos and bos\n",
    "        max_length=MAX_TOKENS,\n",
    "        truncation=True,\n",
    "        pad_to_max_length=True,\n",
    "    )\n",
    "    # shift labels for next token prediction\n",
    "    # set padding token labels to -100 which is ignored in loss computation\n",
    "    output[\"labels\"] = [x[1:] for x in output[\"input_ids\"]]\n",
    "    output[\"labels\"] = [\n",
    "        [-100 if x == tokenizer.pad_token_id else x for x in y]\n",
    "        for y in output[\"labels\"]\n",
    "    ]\n",
    "    # truncate input ids and attention mask to account for label shift\n",
    "    output[\"input_ids\"] = [x[:-1] for x in output[\"input_ids\"]]\n",
    "    output[\"attention_mask\"] = [x[:-1] for x in output[\"attention_mask\"]]\n",
    "    return output\n",
    "\n",
    "\n",
    "data = data.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1adccfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429dc595be3a4b37bba11d246644eb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 59820\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "test_set = test_set.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3e6df0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 18:49:53.832732: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-19 18:49:53.833071: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# prepare for use in tensorflow\n",
    "train_tensor_inputs = tf.convert_to_tensor(data[\"input_ids\"])\n",
    "train_tensor_labels = tf.convert_to_tensor(data[\"labels\"])\n",
    "train_tensor_mask = tf.convert_to_tensor(data[\"attention_mask\"])\n",
    "train = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"input_ids\": train_tensor_inputs, \"attention_mask\": train_tensor_mask},\n",
    "        train_tensor_labels,\n",
    "    )\n",
    ")\n",
    "\n",
    "test_tensor_inputs = tf.convert_to_tensor(test_set[\"input_ids\"])\n",
    "test_tensor_inputs = tf.convert_to_tensor(test_set[\"labels\"])\n",
    "test_tensor_inputs = tf.convert_to_tensor(test_set[\"attention_mask\"])\n",
    "test = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"input_ids\": test_tensor_inputs, \"attention_mask\": test_tensor_inputs},\n",
    "        test_tensor_inputs,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecc233",
   "metadata": {},
   "source": [
    "## Fine-tuning GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3fe29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "BATCH_SIZE_PER_REPLICA = 256\n",
    "EPOCHS = numEpochs\n",
    "INITAL_LEARNING_RATE = 0.001\n",
    "try:\n",
    "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA\n",
    "except NameError as e:\n",
    "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA\n",
    "BUFFER_SIZE = len(train)\n",
    "\n",
    "# prepare data for consumption\n",
    "train_ds = (train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True))\n",
    "test_ds = test.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcd62c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses\n",
    "import tensorflow_privacy \n",
    "from tensorflow_privacy import DPKerasAdamOptimizer\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPAdamOptimizer\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer\n",
    "#from privacy.optimizers.gaussian_query import GaussianAverageQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b1877d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 124448256 \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,448,256\n",
      "Trainable params: 124,448,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Drecreasing learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    INITAL_LEARNING_RATE,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.7,\n",
    "    staircase=True)\n",
    "\n",
    "# initialize model, use_cache=False important! else wrong shape at loss calc\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\n",
    "        \"gpt2\",\n",
    "        use_cache=False,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "#optimizer = tensorflow_privacy.privacy.optimizers.dp_optimizer.DPGradientDescentGaussianOptimizer(l2_norm_clip=10,noise_multiplier=1,num_microbatches=12,learning_rate=0.001)\n",
    "#DPGradientDescentGaussianOptimizer this one officially has bug problems with this version\n",
    "\n",
    "#optimizer = tensorflow_privacy.v1.DPAdamGaussianOptimize(l2_norm_clip=10,noise_multiplier=1,num_microbatches=12,learning_rate=0.001)\n",
    "#optimizer=DPKerasAdamOptimizer(l2_norm_clip=10,noise_multiplier=1,num_microbatches=12)\n",
    "\n",
    "# Create GaussianSumQuery.\n",
    "#dp_sum_query = gaussian_query.GaussianSumQuery(l2_norm_clip=1.0, stddev=0.5)\n",
    "\n",
    "# Create optimizer.\n",
    "#optimizer = tensorflow_privacy.privacy.optimizers.dp_optimizer.DPAdamOptimizer(1, False)\n",
    "#loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "#    labels=labels, logits=logits)\n",
    "\n",
    "#train_op = opt.minimize(loss, global_step=global_step)\n",
    "\n",
    "#optimizer=tf.keras.optimizers.\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "#model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])\n",
    "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdd07db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop training when validation acc starts dropping\n",
    "# Save checkpoint of model after each period\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "\n",
    "PATH_BASE = \"/TML_GPT2\"\n",
    "# Create callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", verbose=1, patience=1, restore_best_weights=True\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3945b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params:\n",
      "batch_size: 256\n",
      "Epochs: 5\n",
      "Step p. Epoch: 510\n",
      "Initial Learning rate: 0.001\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 18:50:01.713428: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-19 18:50:01.716768: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - ETA: 0s - loss: 4.0725 - accuracy: 0.4961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 19:01:25.160917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - 784s 2s/step - loss: 4.0725 - accuracy: 0.4961 - val_loss: 13.8666 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "510/510 [==============================] - ETA: 0s - loss: 3.1066 - accuracy: 0.5251Restoring model weights from the end of the best epoch: 1.\n",
      "510/510 [==============================] - 787s 2s/step - loss: 3.1066 - accuracy: 0.5251 - val_loss: 13.9273 - val_accuracy: 0.0000e+00\n",
      "Epoch 2: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "steps_per_epoch = int(BUFFER_SIZE // BATCH_SIZE)\n",
    "print(\n",
    "    f\"Model Params:\\nbatch_size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\\n\"\n",
    "    f\"Step p. Epoch: {steps_per_epoch}\\n\"\n",
    "    f\"Initial Learning rate: {INITAL_LEARNING_RATE}\"\n",
    ")\n",
    "hist = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11223e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(\n",
    "    {\"train loss\": hist.history[\"loss\"], \"test loss\": hist.history[\"val_loss\"]}\n",
    ").melt()\n",
    "loss[\"epoch\"] = loss.groupby(\"variable\").cumcount() + 1\n",
    "sns.lineplot(x=\"epoch\", y=\"value\", hue=\"variable\", data=loss).set(\n",
    "    title=\"Model loss\",\n",
    "    ylabel=\"\",\n",
    "    xticks=range(1, loss[\"epoch\"].max() + 1),\n",
    "    xticklabels=loss[\"epoch\"].unique(),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55cf72bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'transformer',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'config': {'vocab_size': 50268,\n",
       "  'n_positions': 1024,\n",
       "  'n_embd': 768,\n",
       "  'n_layer': 12,\n",
       "  'n_head': 12,\n",
       "  'n_inner': None,\n",
       "  'activation_function': 'gelu_new',\n",
       "  'resid_pdrop': 0.1,\n",
       "  'embd_pdrop': 0.1,\n",
       "  'attn_pdrop': 0.1,\n",
       "  'layer_norm_epsilon': 1e-05,\n",
       "  'initializer_range': 0.02,\n",
       "  'summary_type': 'cls_index',\n",
       "  'summary_use_proj': True,\n",
       "  'summary_activation': None,\n",
       "  'summary_first_dropout': 0.1,\n",
       "  'summary_proj_to_labels': True,\n",
       "  'scale_attn_weights': True,\n",
       "  'use_cache': False,\n",
       "  'scale_attn_by_inverse_layer_idx': False,\n",
       "  'reorder_and_upcast_attn': False,\n",
       "  'bos_token_id': 50256,\n",
       "  'eos_token_id': 50260,\n",
       "  'return_dict': True,\n",
       "  'output_hidden_states': False,\n",
       "  'output_attentions': False,\n",
       "  'torchscript': False,\n",
       "  'torch_dtype': None,\n",
       "  'use_bfloat16': False,\n",
       "  'pruned_heads': {},\n",
       "  'tie_word_embeddings': True,\n",
       "  'is_encoder_decoder': False,\n",
       "  'is_decoder': False,\n",
       "  'cross_attention_hidden_size': None,\n",
       "  'add_cross_attention': False,\n",
       "  'tie_encoder_decoder': False,\n",
       "  'max_length': 20,\n",
       "  'min_length': 0,\n",
       "  'do_sample': False,\n",
       "  'early_stopping': False,\n",
       "  'num_beams': 1,\n",
       "  'num_beam_groups': 1,\n",
       "  'diversity_penalty': 0.0,\n",
       "  'temperature': 1.0,\n",
       "  'top_k': 50,\n",
       "  'top_p': 1.0,\n",
       "  'typical_p': 1.0,\n",
       "  'repetition_penalty': 1.0,\n",
       "  'length_penalty': 1.0,\n",
       "  'no_repeat_ngram_size': 0,\n",
       "  'encoder_no_repeat_ngram_size': 0,\n",
       "  'bad_words_ids': None,\n",
       "  'num_return_sequences': 1,\n",
       "  'chunk_size_feed_forward': 0,\n",
       "  'output_scores': False,\n",
       "  'return_dict_in_generate': False,\n",
       "  'forced_bos_token_id': None,\n",
       "  'forced_eos_token_id': None,\n",
       "  'remove_invalid_values': False,\n",
       "  'architectures': ['GPT2LMHeadModel'],\n",
       "  'finetuning_task': None,\n",
       "  'id2label': {0: 'LABEL_0', 1: 'LABEL_1'},\n",
       "  'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
       "  'tokenizer_class': None,\n",
       "  'prefix': None,\n",
       "  'pad_token_id': 50265,\n",
       "  'sep_token_id': None,\n",
       "  'decoder_start_token_id': None,\n",
       "  'task_specific_params': {'text-generation': {'do_sample': True,\n",
       "    'max_length': 50}},\n",
       "  'problem_type': None,\n",
       "  '_name_or_path': 'gpt2',\n",
       "  'transformers_version': '4.17.0',\n",
       "  'model_type': 'gpt2',\n",
       "  'n_ctx': 1024}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163cf9ef",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Computing the exposure metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c340565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#greedy_output = model.generate(inputs_test, max_length=50, \n",
    "#    num_beams=5, \n",
    "#    early_stopping=True\n",
    "#)\n",
    "#create the dictionnary \n",
    "#attention! apparently there is something about them being shifted so i need to watchout\n",
    "dct_CD=tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47a70b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[    0,  1999,  1210,  1437, 17672,  1437,     2]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "inputs_test=tokenizer(xt_CD[6][0], return_tensors=\"tf\")\n",
    "print(inputs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eed1d492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return(np.exp(x)/np.exp(x).sum())\n",
    "#outputs\n",
    "#softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7476746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(x,model,dictionary,size,index):\n",
    "    #for a in range(0,len(x)): \n",
    "        #This chuck of code will retreive the prediction score in logits from the model\n",
    "    inputs=tokenizer(x[index][0], return_tensors=\"tf\")\n",
    "    outputs = model(inputs)\n",
    "    p0=outputs[0][:, -1, :]\n",
    "       \n",
    "    #now transfrom logits to probabilities using softmax\n",
    "    p0=p0.numpy()  #transform to numpy for easier handling\n",
    "    p0=softmax(p0)\n",
    "        \n",
    "        #join these probabilities to the vocabulary dictionnary\n",
    "    new_dic={}\n",
    "    for (key, value), num in zip(dictionary.items(), p0[0]): #ATTENTION: the index of [0] is to extract from cell, so we musnt change it\n",
    "        new_dic.update({key:num})\n",
    "        \n",
    "        #here we create numericprobs vec which is vector of length 100 which is the numbers that we can have in random secre\n",
    "    numericProbs_gpt = np.zeros((size), dtype = float)\n",
    "\n",
    "        ############################################################################################################\n",
    "        \n",
    "        #append probabilities to vocab dictionnary\n",
    "        #here we will find each number's value between 0 to 99 in the dct and then we will find its prob in p0 to be the next predicted word\n",
    "        # so in numeric probs we have a vector of length 100 and probs for each number to be the next word\n",
    "    for j in range(size):\n",
    "        numericProbs_gpt[j] = new_dic[str(j)]\n",
    "        \n",
    "    return numericProbs_gpt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3657e8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating exposure...\n"
     ]
    }
   ],
   "source": [
    "# 6. CALCULATE EXPOSURE ====================================\n",
    "\n",
    "print(\"calculating exposure...\")\n",
    "\n",
    "# 6.1 ENUMERATE OVER EVERY POSSIBLE SECRET -----------------\n",
    "#why start is this?\n",
    "start = len(xt_CD)-secretLength*(numDistinctValues**secretLength)\n",
    "\n",
    "#here we have 100 vectors of len 100\n",
    "p0 = np.ones((numDistinctValues, numDistinctValues), dtype = float)\n",
    "for i in range(start, len(xt_CD), 2 * numDistinctValues):\n",
    "    #print(i)\n",
    "    #this k creates 0 to 99 index\n",
    "    k = int((i-start) / (2 * numDistinctValues))\n",
    "    #print(k)\n",
    "    #here in this for loop we will fill each of 100 vectors by numeric probs function\n",
    "    #what is the values in numeric probs?\n",
    "    #here in p0 we have 100 probs value for 100 possible numbers (from 0 to 99) that can be the next prediction\n",
    "    p0[k] = get_prob(xt_CD, model, dct_CD,numDistinctValues, i)\n",
    "    # this is the prediction for the next index\n",
    "    # we know that a secret devide into two parts for prediction, once the first numeric value then the second\n",
    "    p1 = get_prob(xt_CD, model, dct_CD,numDistinctValues,i + 1)\n",
    "    # then here we have prob for a combination each time, what is the prob of observing 09 18 for example\n",
    "    #the len would be 10000 since the we set numDistinctValues to 100\n",
    "    # we have prob for each combination here to see after the phrase \"my permanent code is\"\n",
    "    p0[k] = p0[k][k] * p1\n",
    "\n",
    "    #then we sort these \n",
    "scoresRaw = np.argsort(p0, None)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "baadc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 CALCULATE RANKS OF ALL SECRETS -----------------------\n",
    "d = []\n",
    "for i in range(len(scoresRaw)):\n",
    "    d.append({'rank' : i + 1,\n",
    "              'secret1' : int(scoresRaw[i] / numDistinctValues),\n",
    "              'secret2' : scoresRaw[i] % numDistinctValues,\n",
    "              'secretActual1' : int(insertedSecret.split()[-2]),\n",
    "              'secretActual2' : int(insertedSecret.split()[-1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71753d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "#6.3 CALCULATE EXPOSURE OF INSERTED SECRET ----------------\n",
    "secretRanks = pd.DataFrame(d)\n",
    "secretMatch1 = secretRanks[secretRanks.secret1 == secretRanks.secretActual1]\n",
    "secretMatch2 = int(secretMatch1[secretMatch1.secret2 == secretMatch1.secretActual2]['rank'])\n",
    "\n",
    "exposure = log(bigR, 2) - log(secretMatch2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39d24364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>secret1</th>\n",
       "      <th>secret2</th>\n",
       "      <th>secretActual1</th>\n",
       "      <th>secretActual2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>97</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>37</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rank  secret1  secret2  secretActual1  secretActual2\n",
       "0         1       97       97             73              4\n",
       "1         2       77       97             73              4\n",
       "2         3       97       93             73              4\n",
       "3         4       77       93             73              4\n",
       "4         5       93       97             73              4\n",
       "...     ...      ...      ...            ...            ...\n",
       "9995   9996       37       26             73              4\n",
       "9996   9997        4       30             73              4\n",
       "9997   9998       37       30             73              4\n",
       "9998   9999        4       85             73              4\n",
       "9999  10000       37       85             73              4\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secretRanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27eb22a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9395375120138922"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93beb5",
   "metadata": {},
   "source": [
    "## Calculating exposure for gpt-2 without finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7216bc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! Please ensure your labels are passed as keys in the input dict so that they are accessible to the model during the forward pass. To disable this behaviour, please pass a loss argument, or explicitly pass loss=None if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "#no need for finetuning with the training data, only need the test set\n",
    "#fetch new model and tokenizer\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "\n",
    "tokenizer_raw = AutoTokenizer.from_pretrained('gpt2')\n",
    "model_raw = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id)\n",
    "model_raw.compile(metrics=[metric])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b36a2c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating exposure...\n"
     ]
    }
   ],
   "source": [
    "# 6. CALCULATE EXPOSURE ====================================\n",
    "\n",
    "print(\"calculating exposure...\")\n",
    "\n",
    "# 6.1 ENUMERATE OVER EVERY POSSIBLE SECRET -----------------\n",
    "#why start is this?\n",
    "start = len(xt_CD)-secretLength*(numDistinctValues**secretLength)\n",
    "\n",
    "#here we have 100 vectors of len 100\n",
    "p0 = np.ones((numDistinctValues, numDistinctValues), dtype = float)\n",
    "for i in range(start, len(xt_CD), 2 * numDistinctValues):\n",
    "    #print(i)\n",
    "    #this k creates 0 to 99 index\n",
    "    k = int((i-start) / (2 * numDistinctValues))\n",
    "    #print(k)\n",
    "    #here in this for loop we will fill each of 100 vectors by numeric probs function\n",
    "    #what is the values in numeric probs?\n",
    "    #here in p0 we have 100 probs value for 100 possible numbers (from 0 to 99) that can be the next prediction\n",
    "    p0[k] = get_prob(xt_CD, model_raw, dct_CD,numDistinctValues, i)\n",
    "    # this is the prediction for the next index\n",
    "    # we know that a secret devide into two parts for prediction, once the first numeric value then the second\n",
    "    p1 = get_prob(xt_CD, model_raw, dct_CD,numDistinctValues,i + 1)\n",
    "    # then here we have prob for a combination each time, what is the prob of observing 09 18 for example\n",
    "    #the len would be 10000 since the we set numDistinctValues to 100\n",
    "    # we have prob for each combination here to see after the phrase \"my permanent code is\"\n",
    "    p0[k] = p0[k][k] * p1\n",
    "\n",
    "    #then we sort these \n",
    "scoresRaw = np.argsort(p0, None)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "517935fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 CALCULATE RANKS OF ALL SECRETS -----------------------\n",
    "d = []\n",
    "for i in range(len(scoresRaw)):\n",
    "    d.append({'rank' : i + 1,\n",
    "              'secret1' : int(scoresRaw[i] / numDistinctValues),\n",
    "              'secret2' : scoresRaw[i] % numDistinctValues,\n",
    "              'secretActual1' : int(insertedSecret.split()[-2]),\n",
    "              'secretActual2' : int(insertedSecret.split()[-1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "918a841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "#6.3 CALCULATE EXPOSURE OF INSERTED SECRET ----------------\n",
    "secretRanks = pd.DataFrame(d)\n",
    "secretMatch1 = secretRanks[secretRanks.secret1 == secretRanks.secretActual1]\n",
    "secretMatch2 = int(secretMatch1[secretMatch1.secret2 == secretMatch1.secretActual2]['rank'])\n",
    "\n",
    "exposure = log(bigR, 2) - log(secretMatch2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9fdb04d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15617691087310526"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exposure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
